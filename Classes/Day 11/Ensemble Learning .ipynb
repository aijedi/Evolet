{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of Contents\n",
    "Introduction to Ensemble Learning\n",
    "Basic Ensemble Techniques:\n",
    "1. Max Voting\n",
    "2. Averaging\n",
    "3. Weighted Average\n",
    "\n",
    "#### Advanced Ensemble Techniques\n",
    "1. Stacking\n",
    "2. Bagging\n",
    "3. Boosting\n",
    "\n",
    "#### Algorithms based on Bagging and Boosting\n",
    "1. Bagging meta-estimator\n",
    "2. Random Forest\n",
    "3. AdaBoost\n",
    "4. GBM\n",
    "5. XGB\n",
    "6. Light GBM\n",
    "7. CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Simple Ensemble Techniques\n",
    "In this section, we will look at a few simple but powerful techniques, namely:\n",
    "\n",
    "Max Voting\n",
    "Averaging\n",
    "Weighted Averaging\n",
    "\n",
    "##### 1. Max Voting\n",
    "The max voting method is generally used for classification problems. In this technique, multiple models are used to make predictions for each data point. The predictions by each model are considered as a ‘vote’. The predictions which we get from the majority of the models are used as the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('data/bank_processed_data.csv')\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X = df.drop('deposit_cat', 1)\n",
    "y = df.deposit_cat\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "\n",
    "model1 = LogisticRegression(random_state=1)\n",
    "model2 = tree.DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "\n",
    "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2)], voting='hard')\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the max voting technique, multiple predictions are made for each data point in averaging. In this method, we take an average of predictions from all the models and use it to make the final prediction. Averaging can be used for making predictions in regression problems or while calculating probabilities for classification problems.\n",
    "\n",
    "For example, in the below case, the averaging method would take the average of all the values.\n",
    "\n",
    "i.e. (5+4+5+4+4)/5 = 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model1 = tree.DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "\n",
    "pred1 = model1.predict_proba(X_test)\n",
    "pred2 = model2.predict_proba(X_test)\n",
    "pred3 = model3.predict_proba(X_test)\n",
    "\n",
    "finalpred = (pred1+pred2+pred3)/3\n",
    "print (finalpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Weighted Average"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is an extension of the averaging method. All models are assigned different weights defining the importance of each model for prediction. For instance, if two of your colleagues are critics, while others have no prior experience in this field, then the answers by these two friends are given more importance as compared to the other people.\n",
    "\n",
    "The result is calculated as  [(5*0.23) + (4*0.23) + (5*0.18) + (4*0.18) + (4*0.18)] = 4.41."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "\n",
    "pred1 = model1.predict_proba(X_test)\n",
    "pred2 = model2.predict_proba(X_test)\n",
    "pred3 = model3.predict_proba(X_test)\n",
    "\n",
    "finalpred = (pred1*0.3+pred2*0.3+pred3*0.4)\n",
    "\n",
    "print (finalpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model3.predict_proba([X_test.iloc[-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model3.predict([X_test.iloc[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Advanced Ensemble techniques\n",
    "Now that we have covered the basic ensemble techniques, let’s move on to understanding the advanced techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Stacking\n",
    "Stacking is an ensemble learning technique that uses predictions from multiple models (for example decision tree, knn or svm) to build a new model. This model is used for making predictions on the test set. Below is a step-wise explanation for a simple stacked ensemble:\n",
    "\n",
    "The train set is split into 10 parts.\n",
    "\n",
    "<img src=\"images/image-11.png\">\n",
    "\n",
    "A base model (suppose a decision tree) is fitted on 9 parts and predictions are made for the 10th part. This is done for each part of the train set.\n",
    "\n",
    "<img src=\"images/image-10.png\">\n",
    "\n",
    "The base model (in this case, decision tree) is then fitted on the whole train dataset.\n",
    "Using this model, predictions are made on the test set.\n",
    "\n",
    "<img src=\"images/image-2.png\">\n",
    "\n",
    "Steps 2 to 4 are repeated for another base model (say knn) resulting in another set of predictions for the train set and test set.\n",
    "\n",
    "<img src=\"images/image-3.png\">\n",
    "\n",
    "The predictions from the train set are used as features to build a new model\n",
    "\n",
    "<img src=\"images/image12.png\">\n",
    "\n",
    "This model is used to make final predictions on the test prediction set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We first define a function to make predictions on n-folds of train and test dataset. This function returns the predictions for train and test for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def Stacking(model,train,y,test,n_fold):\n",
    "    \n",
    "    folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n",
    "    \n",
    "    test_pred=np.empty((test.shape[0],1),float)\n",
    "    train_pred=np.empty((0,1),float)\n",
    "    \n",
    "    for train_indices,val_indices in folds.split(train,y.values):\n",
    "        \n",
    "        x_train,x_val = train.iloc[train_indices],train.iloc[val_indices]\n",
    "        y_train,y_val = y.iloc[train_indices],y.iloc[val_indices]\n",
    "\n",
    "        model.fit(X=x_train,y=y_train)\n",
    "        train_pred = model.predict(x_val)\n",
    "        test_pred = model.predict(test)\n",
    "        \n",
    "    return test_pred,train_pred, y_val#, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll create two base models – decision tree and knn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tree.DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "test_pred1 ,train_pred1, y_val_1 = Stacking(model=model1,n_fold=10, train=X_train,test=X_test,y=y_train)\n",
    "\n",
    "train_pred1 = pd.DataFrame(train_pred1)\n",
    "test_pred1 = pd.DataFrame(test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = KNeighborsClassifier()\n",
    "\n",
    "test_pred2 ,train_pred2, y_val_2 =Stacking(model=model2,n_fold=10,train=X_train,test=X_test,y=y_train)\n",
    "\n",
    "train_pred2 = pd.DataFrame(train_pred2)\n",
    "test_pred2 = pd.DataFrame(test_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a third model, logistic regression, on the predictions of the decision tree and knn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.concat([train_pred1, train_pred2], axis=1)\n",
    "df_test = pd.concat([test_pred1, test_pred2], axis=1)\n",
    "y_test_val = y_val_1\n",
    "\n",
    "model = LogisticRegression(random_state=1)\n",
    "model.fit(df_train,y_test_val)\n",
    "model.score(df_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to simplify the above explanation, the stacking model we have created has only two levels. The decision tree and knn models are built at level zero, while a logistic regression model is built at level one. Feel free to create multiple levels in a stacking model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "The idea behind bagging is combining the results of multiple models (for instance, all decision trees) to get a generalized result. Here’s a question: If you create all the models on the same set of data and combine it, will it be useful? There is a high chance that these models will give the same result since they are getting the same input. So how can we solve this problem? One of the techniques is bootstrapping.\n",
    "\n",
    "Bootstrapping is a sampling technique in which we create subsets of observations from the original dataset, with replacement. The size of the subsets is the same as the size of the original set.\n",
    "\n",
    "Bagging (or Bootstrap Aggregating) technique uses these subsets (bags) to get a fair idea of the distribution (complete set). The size of subsets created for bagging may be less than the original set.\n",
    "\n",
    "<img src=\"images/capture.png\">\n",
    "\n",
    "1. Multiple subsets are created from the original dataset, selecting observations with replacement.\n",
    "2. A base model (weak model) is created on each of these subsets.\n",
    "3. The models run in parallel and are independent of each other.\n",
    "4. The final predictions are determined by combining the predictions from all the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting\n",
    "Before we go further, here’s another question for you: If a data point is incorrectly predicted by the first model, and then the next (probably all models), will combining the predictions provide better results? Such situations are taken care of by boosting.\n",
    "\n",
    "Boosting is a sequential process, where each subsequent model attempts to correct the errors of the previous model. The succeeding models are dependent on the previous model. Let’s understand the way boosting works in the below steps.\n",
    "\n",
    "1. A subset is created from the original dataset.\n",
    "2. Initially, all data points are given equal weights.\n",
    "3. A base model is created on this subset.\n",
    "4. This model is used to make predictions on the whole dataset.\n",
    "\n",
    "<img src=\"images/capture2.png\">\n",
    "\n",
    "5. Errors are calculated using the actual values and predicted values.\n",
    "6. The observations which are incorrectly predicted, are given higher weights.\n",
    "(Here, the three misclassified blue-plus points will be given higher weights)\n",
    "7. Another model is created and predictions are made on the dataset.\n",
    "(This model tries to correct the errors from the previous model)\n",
    "\n",
    "<img src=\"images/capture3.png\">\n",
    "\n",
    "8. Similarly, multiple models are created, each correcting the errors of the previous model.\n",
    "9. The final model (strong learner) is the weighted mean of all the models (weak learners).\n",
    "\n",
    "Thus, the boosting algorithm combines a number of weak learners to form a strong learner. The individual models would not perform well on the entire dataset, but they work well for some part of the dataset. Thus, each model actually boosts the performance of the ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Algorithms based on Bagging and Boosting\n",
    "Bagging and Boosting are two of the most commonly used techniques in machine learning. In this section, we will look at them in detail. Following are the algorithms we will be focusing on:\n",
    "\n",
    "Bagging algorithms:\n",
    "\n",
    "1. Bagging meta-estimator\n",
    "2. Random forest\n",
    "\n",
    "Boosting algorithms:\n",
    "1. AdaBoost\n",
    "2. GBM\n",
    "3. XGBM\n",
    "4. Light GBM\n",
    "5. CatBoost\n",
    "\n",
    "For all the algorithms discussed in this section, we will follow this procedure:\n",
    "\n",
    "Introduction to the algorithm\n",
    "Sample code\n",
    "Parameters\n",
    "For this article, I have used the Loan Prediction Problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#reading the dataset\n",
    "df=pd.read_csv(\"data/train_ctrUa4K.csv\")\n",
    "\n",
    "#filling missing values\n",
    "df['Gender'].fillna('Male', inplace=True)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[[ 'Gender', 'Married', 'Dependents', 'Education',\n",
    "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "       'Loan_Amount_Term', 'Credit_History', 'Property_Area']]\n",
    "\n",
    "y =  df['Loan_Status']\n",
    "\n",
    "X =  pd.get_dummies(X)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1. Bagging meta-estimator\n",
    "Bagging meta-estimator is an ensembling algorithm that can be used for both classification (BaggingClassifier) and regression (BaggingRegressor) problems. It follows the typical bagging technique to make predictions. Following are the steps for the bagging meta-estimator algorithm:\n",
    "\n",
    "1. Random subsets are created from the original dataset (Bootstrapping).\n",
    "2. The subset of the dataset includes all features.\n",
    "3. A user-specified base estimator is fitted on each of these smaller sets.\n",
    "4. Predictions from each model are combined to get the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7027027027027027"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1), n_jobs=-1)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters used in the  algorithms:\n",
    "\n",
    "##### 1. base_estimator:\n",
    "It defines the base estimator to fit on random subsets of the dataset.\n",
    "When nothing is specified, the base estimator is a decision tree.\n",
    "\n",
    "##### 2. n_estimators:\n",
    "It is the number of base estimators to be created.\n",
    "The number of estimators should be carefully tuned as a large number would take a very long time to run, while a very small number might not provide the best results.\n",
    "\n",
    "##### 3. max_samples:\n",
    "This parameter controls the size of the subsets.\n",
    "It is the maximum number of samples to train each base estimator.\n",
    "\n",
    "##### 4. max_features:\n",
    "Controls the number of features to draw from the whole dataset.\n",
    "It defines the maximum number of features required to train each base estimator.\n",
    "\n",
    "##### 5. n_jobs:\n",
    "The number of jobs to run in parallel.\n",
    "Set this value equal to the cores in your system.\n",
    "If -1, the number of jobs is set to the number of cores.\n",
    "\n",
    "##### 6. random_state:\n",
    "It specifies the method of random split. When random state value is same for two models, the random selection is same for both models.\n",
    "This parameter is useful when you want to compare different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost\n",
    "Adaptive boosting or AdaBoost is one of the simplest boosting algorithms. Usually, decision trees are used for modelling. Multiple sequential models are created, each correcting the errors from the last model. AdaBoost assigns weights to the observations which are incorrectly predicted and the subsequent model works to predict these values correctly.\n",
    "\n",
    "Below are the steps for performing the AdaBoost algorithm:\n",
    "\n",
    "1. Initially, all observations in the dataset are given equal weights.\n",
    "2. A model is built on a subset of data.\n",
    "3. Using this model, predictions are made on the whole dataset.\n",
    "4. Errors are calculated by comparing the predictions and actual values.\n",
    "5. While creating the next model, higher weights are given to the data points which were predicted incorrectly.\n",
    "6. Weights can be determined using the error value. For instance, higher the error more is the weight assigned to the observation.\n",
    "7. This process is repeated until the error function does not change, or the maximum limit of the number of estimators is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7567567567567568"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "\n",
    "##### 1. base_estimators:\n",
    "It helps to specify the type of base estimator, that is, the machine learning algorithm to be used as base learner.\n",
    "\n",
    "##### 2. n_estimators:\n",
    "It defines the number of base estimators.\n",
    "The default value is 10, but you should keep a higher value to get better performance.\n",
    "\n",
    "##### 3. learning_rate:\n",
    "This parameter controls the contribution of the estimators in the final combination.\n",
    "There is a trade-off between learning_rate and n_estimators.\n",
    "\n",
    "##### 4. max_depth:\n",
    "Defines the maximum depth of the individual estimator.\n",
    "Tune this parameter for best performance.\n",
    "\n",
    "##### 5. n_jobs\n",
    "Specifies the number of processors it is allowed to use.\n",
    "Set value to -1 for maximum processors allowed.\n",
    "\n",
    "##### 6. random_state :\n",
    "An integer value to specify the random data split.\n",
    "A definite value of random_state will always produce same results if given with same parameters and training data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting (GBM)\n",
    "Gradient Boosting or GBM is another ensemble machine learning algorithm that works for both regression and classification problems. GBM uses the boosting technique, combining a number of weak learners to form a strong learner. Regression trees used as a base learner, each subsequent tree in series is built on the errors calculated by the previous tree.\n",
    "\n",
    "<img src=\"images/gb1.png\">\n",
    "\n",
    "<img src=\"images/gb2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7891891891891892"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model= GradientBoostingClassifier(learning_rate=0.01,random_state=1)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "\n",
    "##### 1. min_samples_split\n",
    "Defines the minimum number of samples (or observations) which are required in a node to be considered for splitting.\n",
    "Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n",
    "\n",
    "##### 2. min_samples_leaf\n",
    "Defines the minimum samples required in a terminal or leaf node.\n",
    "Generally, lower values should be chosen for imbalanced class problems because the regions in which the minority class will be in the majority will be very small.\n",
    "\n",
    "##### 3. min_weight_fraction_leaf\n",
    "Similar to min_samples_leaf but defined as a fraction of the total number of observations instead of an integer.\n",
    "\n",
    "##### 4. max_depth\n",
    "The maximum depth of a tree.\n",
    "Used to control over-fitting as higher depth will allow the model to learn relations very specific to a particular sample.\n",
    "Should be tuned using CV.\n",
    "\n",
    "##### 5. max_leaf_nodes\n",
    "The maximum number of terminal nodes or leaves in a tree.\n",
    "Can be defined in place of max_depth. Since binary trees are created, a depth of ‘n’ would produce a maximum of 2^n leaves.\n",
    "If this is defined, GBM will ignore max_depth.\n",
    "\n",
    "##### 6. max_features\n",
    "The number of features to consider while searching for the best split. These will be randomly selected.\n",
    "As a thumb-rule, the square root of the total number of features works great but we should check up to 30-40% of the total number of features.\n",
    "Higher values can lead to over-fitting but it generally depends on a case to case scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "XGBoost (extreme Gradient Boosting) is an advanced implementation of the gradient boosting algorithm. XGBoost has proved to be a highly effective ML algorithm, extensively used in machine learning competitions and hackathons. XGBoost has high predictive power and is almost 10 times faster than the other gradient boosting techniques. It also includes a variety of regularization which reduces overfitting and improves overall performance. Hence it is also known as ‘regularized boosting‘ technique.\n",
    "\n",
    "Let us see how XGBoost is comparatively better than other techniques:\n",
    "\n",
    "##### 1. Regularization:\n",
    "Standard GBM implementation has no regularisation like XGBoost.\n",
    "Thus XGBoost also helps to reduce overfitting.\n",
    "\n",
    "##### 2. Parallel Processing:\n",
    "XGBoost implements parallel processing and is faster than GBM .\n",
    "XGBoost also supports implementation on Hadoop.\n",
    "\n",
    "##### 3. High Flexibility:\n",
    "XGBoost allows users to define custom optimization objectives and evaluation criteria adding a whole new dimension to the model.\n",
    "\n",
    "##### 4. Handling Missing Values:\n",
    "XGBoost has an in-built routine to handle missing values.\n",
    "\n",
    "##### 5. Tree Pruning:\n",
    "XGBoost makes splits up to the max_depth specified and then starts pruning the tree backwards and removes splits beyond which there is no positive gain.\n",
    "\n",
    "##### 6. Built-in Cross-Validation:\n",
    "XGBoost allows a user to run a cross-validation at each iteration of the boosting process and thus it is easy to get the exact optimum number of boosting iterations in a single run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since XGBoost takes care of the missing values itself, you do not have to impute the missing values. You can skip the step for missing value imputation from the code mentioned above. Follow the remaining steps as always and then apply xgboost as below.\n",
    "\n",
    "##### Working on bank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>default_cat</th>\n",
       "      <th>housing_cat</th>\n",
       "      <th>loan_cat</th>\n",
       "      <th>deposit_cat</th>\n",
       "      <th>recent_pdays</th>\n",
       "      <th>...</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>education_primary</th>\n",
       "      <th>education_secondary</th>\n",
       "      <th>education_tertiary</th>\n",
       "      <th>education_unknown</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>2343</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>1270</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>2476</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>184</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  balance  duration  campaign  previous  default_cat  housing_cat  \\\n",
       "0   59     2343      1042         1         0            0            1   \n",
       "1   56       45      1467         1         0            0            0   \n",
       "2   41     1270      1389         1         0            0            1   \n",
       "3   55     2476       579         1         0            0            1   \n",
       "4   54      184       673         2         0            0            0   \n",
       "\n",
       "   loan_cat  deposit_cat  recent_pdays  ...  marital_divorced  \\\n",
       "0         0            1        0.0001  ...                 0   \n",
       "1         0            1        0.0001  ...                 0   \n",
       "2         0            1        0.0001  ...                 0   \n",
       "3         0            1        0.0001  ...                 0   \n",
       "4         0            1        0.0001  ...                 0   \n",
       "\n",
       "   marital_married  marital_single  education_primary  education_secondary  \\\n",
       "0                1               0                  0                    1   \n",
       "1                1               0                  0                    1   \n",
       "2                1               0                  0                    1   \n",
       "3                1               0                  0                    1   \n",
       "4                1               0                  0                    0   \n",
       "\n",
       "   education_tertiary  education_unknown  poutcome_failure  poutcome_success  \\\n",
       "0                   0                  0                 0                 0   \n",
       "1                   0                  0                 0                 0   \n",
       "2                   0                  0                 0                 0   \n",
       "3                   0                  0                 0                 0   \n",
       "4                   1                  0                 0                 0   \n",
       "\n",
       "   poutcome_unknown  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('data/bank_processed_data.csv')\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X = df.drop('deposit_cat', 1)\n",
    "y = df.deposit_cat\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7728412755284844"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "\n",
    "##### 1. nthread\n",
    "This is used for parallel processing and the number of cores in the system should be entered..\n",
    "If you wish to run on all cores, do not input this value. The algorithm will detect it automatically.\n",
    "\n",
    "##### 2. eta\n",
    "Analogous to learning rate in GBM.\n",
    "Makes the model more robust by shrinking the weights on each step.\n",
    "\n",
    "##### 3. min_child_weight\n",
    "Defines the minimum sum of weights of all observations required in a child.\n",
    "Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n",
    "\n",
    "##### 4. max_depth\n",
    "It is used to define the maximum depth.\n",
    "Higher depth will allow the model to learn relations very specific to a particular sample.\n",
    "\n",
    "##### 5. max_leaf_nodes\n",
    "The maximum number of terminal nodes or leaves in a tree.\n",
    "Can be defined in place of max_depth. Since binary trees are created, a depth of ‘n’ would produce a maximum of 2^n leaves.\n",
    "If this is defined, GBM will ignore max_depth.\n",
    "\n",
    "##### 6. gamma\n",
    "A node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split.\n",
    "Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned.\n",
    "\n",
    "##### 7. subsample\n",
    "Same as the subsample of GBM. Denotes the fraction of observations to be randomly sampled for each tree.\n",
    "Lower values make the algorithm more conservative and prevent overfitting but values that are too small might lead to under-fitting.\n",
    "\n",
    "##### 8. colsample_bytree\n",
    "It is similar to max_features in GBM.\n",
    "Denotes the fraction of columns to be randomly sampled for each tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Light GBM\n",
    "Before discussing how Light GBM works, let’s first understand why we need this algorithm when we have so many others (like the ones we have seen above). Light GBM beats all the other algorithms when the dataset is extremely large. Compared to the other algorithms, Light GBM takes lesser time to run on a huge dataset.\n",
    "\n",
    "LightGBM is a gradient boosting framework that uses tree-based algorithms and follows leaf-wise approach while other algorithms work in a level-wise approach pattern. The images below will help you understand the difference in a better way.\n",
    "\n",
    "<img src=\"images/lgb.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train_data = lgb.Dataset(X_train,label=y_train)\n",
    "\n",
    "#define parameters\n",
    "params = {'learning_rate':0.001}\n",
    "\n",
    "model= lgb.train(params, train_data, 100) \n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "for i in range(0,185):\n",
    "    if y_pred[i]>=0.5: \n",
    "           y_pred[i]=1\n",
    "    else: \n",
    "           y_pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lgb2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost\n",
    "Handling categorical variables is a tedious process, especially when you have a large number of such variables. When your categorical variables have too many labels (i.e. they are highly cardinal), performing one-hot-encoding on them exponentially increases the dimensionality and it becomes really difficult to work with the dataset.\n",
    "\n",
    "CatBoost can automatically deal with categorical variables and does not require extensive data preprocessing like other machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.097531\n",
      "0:\tlearn: 0.6605438\ttest: 0.6630435\tbest: 0.6630435 (0)\ttotal: 82.4ms\tremaining: 1m 22s\n",
      "1:\tlearn: 0.6274847\ttest: 0.6338798\tbest: 0.6338798 (1)\ttotal: 185ms\tremaining: 1m 32s\n",
      "2:\tlearn: 0.5972543\ttest: 0.6069457\tbest: 0.6069457 (2)\ttotal: 299ms\tremaining: 1m 39s\n",
      "3:\tlearn: 0.5747952\ttest: 0.5853265\tbest: 0.5853265 (3)\ttotal: 387ms\tremaining: 1m 36s\n",
      "4:\tlearn: 0.5568137\ttest: 0.5684063\tbest: 0.5684063 (4)\ttotal: 517ms\tremaining: 1m 42s\n",
      "5:\tlearn: 0.5386751\ttest: 0.5519826\tbest: 0.5519826 (5)\ttotal: 610ms\tremaining: 1m 41s\n",
      "6:\tlearn: 0.5272078\ttest: 0.5417834\tbest: 0.5417834 (6)\ttotal: 721ms\tremaining: 1m 42s\n",
      "7:\tlearn: 0.5171783\ttest: 0.5325956\tbest: 0.5325956 (7)\ttotal: 824ms\tremaining: 1m 42s\n",
      "8:\tlearn: 0.5068132\ttest: 0.5232998\tbest: 0.5232998 (8)\ttotal: 959ms\tremaining: 1m 45s\n",
      "9:\tlearn: 0.4999544\ttest: 0.5180653\tbest: 0.5180653 (9)\ttotal: 1.08s\tremaining: 1m 46s\n",
      "10:\tlearn: 0.4938210\ttest: 0.5130244\tbest: 0.5130244 (10)\ttotal: 1.19s\tremaining: 1m 46s\n",
      "11:\tlearn: 0.4869566\ttest: 0.5075121\tbest: 0.5075121 (11)\ttotal: 1.27s\tremaining: 1m 45s\n",
      "12:\tlearn: 0.4816336\ttest: 0.5031667\tbest: 0.5031667 (12)\ttotal: 1.37s\tremaining: 1m 44s\n",
      "13:\tlearn: 0.4773912\ttest: 0.4998522\tbest: 0.4998522 (13)\ttotal: 1.48s\tremaining: 1m 44s\n",
      "14:\tlearn: 0.4735907\ttest: 0.4971194\tbest: 0.4971194 (14)\ttotal: 1.59s\tremaining: 1m 44s\n",
      "15:\tlearn: 0.4719622\ttest: 0.4958466\tbest: 0.4958466 (15)\ttotal: 1.65s\tremaining: 1m 41s\n",
      "16:\tlearn: 0.4697465\ttest: 0.4947979\tbest: 0.4947979 (16)\ttotal: 1.77s\tremaining: 1m 42s\n",
      "17:\tlearn: 0.4660841\ttest: 0.4920714\tbest: 0.4920714 (17)\ttotal: 1.85s\tremaining: 1m 41s\n",
      "18:\tlearn: 0.4625502\ttest: 0.4901656\tbest: 0.4901656 (18)\ttotal: 1.95s\tremaining: 1m 40s\n",
      "19:\tlearn: 0.4607340\ttest: 0.4890769\tbest: 0.4890769 (19)\ttotal: 2.04s\tremaining: 1m 40s\n",
      "20:\tlearn: 0.4592297\ttest: 0.4879701\tbest: 0.4879701 (20)\ttotal: 2.11s\tremaining: 1m 38s\n",
      "21:\tlearn: 0.4570593\ttest: 0.4864121\tbest: 0.4864121 (21)\ttotal: 2.23s\tremaining: 1m 39s\n",
      "22:\tlearn: 0.4556480\ttest: 0.4855964\tbest: 0.4855964 (22)\ttotal: 2.34s\tremaining: 1m 39s\n",
      "23:\tlearn: 0.4548032\ttest: 0.4848471\tbest: 0.4848471 (23)\ttotal: 2.43s\tremaining: 1m 38s\n",
      "24:\tlearn: 0.4531473\ttest: 0.4836675\tbest: 0.4836675 (24)\ttotal: 2.54s\tremaining: 1m 38s\n",
      "25:\tlearn: 0.4523909\ttest: 0.4830271\tbest: 0.4830271 (25)\ttotal: 2.62s\tremaining: 1m 38s\n",
      "26:\tlearn: 0.4508496\ttest: 0.4824112\tbest: 0.4824112 (26)\ttotal: 2.73s\tremaining: 1m 38s\n",
      "27:\tlearn: 0.4503033\ttest: 0.4819315\tbest: 0.4819315 (27)\ttotal: 2.8s\tremaining: 1m 37s\n",
      "28:\tlearn: 0.4500911\ttest: 0.4815450\tbest: 0.4815450 (28)\ttotal: 2.86s\tremaining: 1m 35s\n",
      "29:\tlearn: 0.4491062\ttest: 0.4805385\tbest: 0.4805385 (29)\ttotal: 2.97s\tremaining: 1m 36s\n",
      "30:\tlearn: 0.4484117\ttest: 0.4797486\tbest: 0.4797486 (30)\ttotal: 3.08s\tremaining: 1m 36s\n",
      "31:\tlearn: 0.4482559\ttest: 0.4795145\tbest: 0.4795145 (31)\ttotal: 3.16s\tremaining: 1m 35s\n",
      "32:\tlearn: 0.4470276\ttest: 0.4788467\tbest: 0.4788467 (32)\ttotal: 3.27s\tremaining: 1m 35s\n",
      "33:\tlearn: 0.4469175\ttest: 0.4784731\tbest: 0.4784731 (33)\ttotal: 3.32s\tremaining: 1m 34s\n",
      "34:\tlearn: 0.4466591\ttest: 0.4779777\tbest: 0.4779777 (34)\ttotal: 3.36s\tremaining: 1m 32s\n",
      "35:\tlearn: 0.4452116\ttest: 0.4770290\tbest: 0.4770290 (35)\ttotal: 3.45s\tremaining: 1m 32s\n",
      "36:\tlearn: 0.4452113\ttest: 0.4770330\tbest: 0.4770290 (35)\ttotal: 3.52s\tremaining: 1m 31s\n",
      "37:\tlearn: 0.4444189\ttest: 0.4764610\tbest: 0.4764610 (37)\ttotal: 3.71s\tremaining: 1m 33s\n",
      "38:\tlearn: 0.4439662\ttest: 0.4765496\tbest: 0.4764610 (37)\ttotal: 3.83s\tremaining: 1m 34s\n",
      "39:\tlearn: 0.4431702\ttest: 0.4760601\tbest: 0.4760601 (39)\ttotal: 3.92s\tremaining: 1m 34s\n",
      "40:\tlearn: 0.4426348\ttest: 0.4756990\tbest: 0.4756990 (40)\ttotal: 4.01s\tremaining: 1m 33s\n",
      "41:\tlearn: 0.4420436\ttest: 0.4753017\tbest: 0.4753017 (41)\ttotal: 4.11s\tremaining: 1m 33s\n",
      "42:\tlearn: 0.4416779\ttest: 0.4750848\tbest: 0.4750848 (42)\ttotal: 4.17s\tremaining: 1m 32s\n",
      "43:\tlearn: 0.4416759\ttest: 0.4750873\tbest: 0.4750848 (42)\ttotal: 4.2s\tremaining: 1m 31s\n",
      "44:\tlearn: 0.4410217\ttest: 0.4747120\tbest: 0.4747120 (44)\ttotal: 4.28s\tremaining: 1m 30s\n",
      "45:\tlearn: 0.4406927\ttest: 0.4745702\tbest: 0.4745702 (45)\ttotal: 4.35s\tremaining: 1m 30s\n",
      "46:\tlearn: 0.4404300\ttest: 0.4743678\tbest: 0.4743678 (46)\ttotal: 4.43s\tremaining: 1m 29s\n",
      "47:\tlearn: 0.4395418\ttest: 0.4738526\tbest: 0.4738526 (47)\ttotal: 4.53s\tremaining: 1m 29s\n",
      "48:\tlearn: 0.4393186\ttest: 0.4737739\tbest: 0.4737739 (48)\ttotal: 4.6s\tremaining: 1m 29s\n",
      "49:\tlearn: 0.4384670\ttest: 0.4731458\tbest: 0.4731458 (49)\ttotal: 4.69s\tremaining: 1m 29s\n",
      "50:\tlearn: 0.4384670\ttest: 0.4731466\tbest: 0.4731458 (49)\ttotal: 4.71s\tremaining: 1m 27s\n",
      "51:\tlearn: 0.4384284\ttest: 0.4730342\tbest: 0.4730342 (51)\ttotal: 4.74s\tremaining: 1m 26s\n",
      "52:\tlearn: 0.4379188\ttest: 0.4726632\tbest: 0.4726632 (52)\ttotal: 4.84s\tremaining: 1m 26s\n",
      "53:\tlearn: 0.4371230\ttest: 0.4723887\tbest: 0.4723887 (53)\ttotal: 5.01s\tremaining: 1m 27s\n",
      "54:\tlearn: 0.4365396\ttest: 0.4719028\tbest: 0.4719028 (54)\ttotal: 5.16s\tremaining: 1m 28s\n",
      "55:\tlearn: 0.4362401\ttest: 0.4716772\tbest: 0.4716772 (55)\ttotal: 5.23s\tremaining: 1m 28s\n",
      "56:\tlearn: 0.4362051\ttest: 0.4715577\tbest: 0.4715577 (56)\ttotal: 5.27s\tremaining: 1m 27s\n",
      "57:\tlearn: 0.4362051\ttest: 0.4715577\tbest: 0.4715577 (56)\ttotal: 5.31s\tremaining: 1m 26s\n",
      "58:\tlearn: 0.4362051\ttest: 0.4715577\tbest: 0.4715577 (56)\ttotal: 5.33s\tremaining: 1m 25s\n",
      "59:\tlearn: 0.4359819\ttest: 0.4714709\tbest: 0.4714709 (59)\ttotal: 5.38s\tremaining: 1m 24s\n",
      "60:\tlearn: 0.4359819\ttest: 0.4714709\tbest: 0.4714709 (59)\ttotal: 5.42s\tremaining: 1m 23s\n",
      "61:\tlearn: 0.4356872\ttest: 0.4715508\tbest: 0.4714709 (59)\ttotal: 5.5s\tremaining: 1m 23s\n",
      "62:\tlearn: 0.4356872\ttest: 0.4715505\tbest: 0.4714709 (59)\ttotal: 5.53s\tremaining: 1m 22s\n",
      "63:\tlearn: 0.4356872\ttest: 0.4715503\tbest: 0.4714709 (59)\ttotal: 5.55s\tremaining: 1m 21s\n",
      "64:\tlearn: 0.4351688\ttest: 0.4708117\tbest: 0.4708117 (64)\ttotal: 5.64s\tremaining: 1m 21s\n",
      "65:\tlearn: 0.4351688\ttest: 0.4708117\tbest: 0.4708117 (65)\ttotal: 5.67s\tremaining: 1m 20s\n",
      "66:\tlearn: 0.4349922\ttest: 0.4707467\tbest: 0.4707467 (66)\ttotal: 5.72s\tremaining: 1m 19s\n",
      "67:\tlearn: 0.4349922\ttest: 0.4707467\tbest: 0.4707467 (66)\ttotal: 5.75s\tremaining: 1m 18s\n",
      "68:\tlearn: 0.4346902\ttest: 0.4704763\tbest: 0.4704763 (68)\ttotal: 5.85s\tremaining: 1m 18s\n",
      "69:\tlearn: 0.4343589\ttest: 0.4701553\tbest: 0.4701553 (69)\ttotal: 5.93s\tremaining: 1m 18s\n",
      "70:\tlearn: 0.4343297\ttest: 0.4702282\tbest: 0.4701553 (69)\ttotal: 5.97s\tremaining: 1m 18s\n",
      "71:\tlearn: 0.4340750\ttest: 0.4700833\tbest: 0.4700833 (71)\ttotal: 6.09s\tremaining: 1m 18s\n",
      "72:\tlearn: 0.4336957\ttest: 0.4700956\tbest: 0.4700833 (71)\ttotal: 6.18s\tremaining: 1m 18s\n",
      "73:\tlearn: 0.4328640\ttest: 0.4696790\tbest: 0.4696790 (73)\ttotal: 6.3s\tremaining: 1m 18s\n",
      "74:\tlearn: 0.4322243\ttest: 0.4692890\tbest: 0.4692890 (74)\ttotal: 6.41s\tremaining: 1m 19s\n",
      "75:\tlearn: 0.4322243\ttest: 0.4692910\tbest: 0.4692890 (74)\ttotal: 6.45s\tremaining: 1m 18s\n",
      "76:\tlearn: 0.4318790\ttest: 0.4689578\tbest: 0.4689578 (76)\ttotal: 6.53s\tremaining: 1m 18s\n",
      "77:\tlearn: 0.4318195\ttest: 0.4689247\tbest: 0.4689247 (77)\ttotal: 6.59s\tremaining: 1m 17s\n",
      "78:\tlearn: 0.4318195\ttest: 0.4689252\tbest: 0.4689247 (77)\ttotal: 6.62s\tremaining: 1m 17s\n",
      "79:\tlearn: 0.4314616\ttest: 0.4687205\tbest: 0.4687205 (79)\ttotal: 6.72s\tremaining: 1m 17s\n",
      "80:\tlearn: 0.4311080\ttest: 0.4683132\tbest: 0.4683132 (80)\ttotal: 6.83s\tremaining: 1m 17s\n",
      "81:\tlearn: 0.4308358\ttest: 0.4680990\tbest: 0.4680990 (81)\ttotal: 6.92s\tremaining: 1m 17s\n",
      "82:\tlearn: 0.4301617\ttest: 0.4680425\tbest: 0.4680425 (82)\ttotal: 7.01s\tremaining: 1m 17s\n",
      "83:\tlearn: 0.4297518\ttest: 0.4679891\tbest: 0.4679891 (83)\ttotal: 7.12s\tremaining: 1m 17s\n",
      "84:\tlearn: 0.4297488\ttest: 0.4679893\tbest: 0.4679891 (83)\ttotal: 7.17s\tremaining: 1m 17s\n",
      "85:\tlearn: 0.4297026\ttest: 0.4679633\tbest: 0.4679633 (85)\ttotal: 7.2s\tremaining: 1m 16s\n",
      "86:\tlearn: 0.4295670\ttest: 0.4677937\tbest: 0.4677937 (86)\ttotal: 7.32s\tremaining: 1m 16s\n",
      "87:\tlearn: 0.4294916\ttest: 0.4677794\tbest: 0.4677794 (87)\ttotal: 7.37s\tremaining: 1m 16s\n",
      "88:\tlearn: 0.4294620\ttest: 0.4677632\tbest: 0.4677632 (88)\ttotal: 7.43s\tremaining: 1m 16s\n",
      "89:\tlearn: 0.4289253\ttest: 0.4676837\tbest: 0.4676837 (89)\ttotal: 7.52s\tremaining: 1m 16s\n",
      "90:\tlearn: 0.4288664\ttest: 0.4677620\tbest: 0.4676837 (89)\ttotal: 7.58s\tremaining: 1m 15s\n",
      "91:\tlearn: 0.4286145\ttest: 0.4676730\tbest: 0.4676730 (91)\ttotal: 7.67s\tremaining: 1m 15s\n",
      "92:\tlearn: 0.4279551\ttest: 0.4671371\tbest: 0.4671371 (92)\ttotal: 7.76s\tremaining: 1m 15s\n",
      "93:\tlearn: 0.4278384\ttest: 0.4672236\tbest: 0.4671371 (92)\ttotal: 7.85s\tremaining: 1m 15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94:\tlearn: 0.4277773\ttest: 0.4672891\tbest: 0.4671371 (92)\ttotal: 7.9s\tremaining: 1m 15s\n",
      "95:\tlearn: 0.4277354\ttest: 0.4673260\tbest: 0.4671371 (92)\ttotal: 7.95s\tremaining: 1m 14s\n",
      "96:\tlearn: 0.4274220\ttest: 0.4673706\tbest: 0.4671371 (92)\ttotal: 8.03s\tremaining: 1m 14s\n",
      "97:\tlearn: 0.4266345\ttest: 0.4670343\tbest: 0.4670343 (97)\ttotal: 8.15s\tremaining: 1m 15s\n",
      "98:\tlearn: 0.4263442\ttest: 0.4670401\tbest: 0.4670343 (97)\ttotal: 8.22s\tremaining: 1m 14s\n",
      "99:\tlearn: 0.4260776\ttest: 0.4668694\tbest: 0.4668694 (99)\ttotal: 8.32s\tremaining: 1m 14s\n",
      "100:\tlearn: 0.4254152\ttest: 0.4666101\tbest: 0.4666101 (100)\ttotal: 8.43s\tremaining: 1m 15s\n",
      "101:\tlearn: 0.4250122\ttest: 0.4664450\tbest: 0.4664450 (101)\ttotal: 8.52s\tremaining: 1m 15s\n",
      "102:\tlearn: 0.4250035\ttest: 0.4664332\tbest: 0.4664332 (102)\ttotal: 8.56s\tremaining: 1m 14s\n",
      "103:\tlearn: 0.4249826\ttest: 0.4663916\tbest: 0.4663916 (103)\ttotal: 8.6s\tremaining: 1m 14s\n",
      "104:\tlearn: 0.4244347\ttest: 0.4663079\tbest: 0.4663079 (104)\ttotal: 8.69s\tremaining: 1m 14s\n",
      "105:\tlearn: 0.4239932\ttest: 0.4660747\tbest: 0.4660747 (105)\ttotal: 8.79s\tremaining: 1m 14s\n",
      "106:\tlearn: 0.4236530\ttest: 0.4658314\tbest: 0.4658314 (106)\ttotal: 8.89s\tremaining: 1m 14s\n",
      "107:\tlearn: 0.4234776\ttest: 0.4660385\tbest: 0.4658314 (106)\ttotal: 8.97s\tremaining: 1m 14s\n",
      "108:\tlearn: 0.4230108\ttest: 0.4659778\tbest: 0.4658314 (106)\ttotal: 9.09s\tremaining: 1m 14s\n",
      "109:\tlearn: 0.4230082\ttest: 0.4659773\tbest: 0.4658314 (106)\ttotal: 9.13s\tremaining: 1m 13s\n",
      "110:\tlearn: 0.4226020\ttest: 0.4660684\tbest: 0.4658314 (106)\ttotal: 9.21s\tremaining: 1m 13s\n",
      "111:\tlearn: 0.4222210\ttest: 0.4656894\tbest: 0.4656894 (111)\ttotal: 9.31s\tremaining: 1m 13s\n",
      "112:\tlearn: 0.4221643\ttest: 0.4655836\tbest: 0.4655836 (112)\ttotal: 9.41s\tremaining: 1m 13s\n",
      "113:\tlearn: 0.4218865\ttest: 0.4654588\tbest: 0.4654588 (113)\ttotal: 9.5s\tremaining: 1m 13s\n",
      "114:\tlearn: 0.4216323\ttest: 0.4655017\tbest: 0.4654588 (113)\ttotal: 9.6s\tremaining: 1m 13s\n",
      "115:\tlearn: 0.4212654\ttest: 0.4653025\tbest: 0.4653025 (115)\ttotal: 9.75s\tremaining: 1m 14s\n",
      "116:\tlearn: 0.4212654\ttest: 0.4653007\tbest: 0.4653007 (116)\ttotal: 9.83s\tremaining: 1m 14s\n",
      "117:\tlearn: 0.4209866\ttest: 0.4651038\tbest: 0.4651038 (117)\ttotal: 9.94s\tremaining: 1m 14s\n",
      "118:\tlearn: 0.4204839\ttest: 0.4650093\tbest: 0.4650093 (118)\ttotal: 10.1s\tremaining: 1m 14s\n",
      "119:\tlearn: 0.4203024\ttest: 0.4648769\tbest: 0.4648769 (119)\ttotal: 10.2s\tremaining: 1m 14s\n",
      "120:\tlearn: 0.4199829\ttest: 0.4649657\tbest: 0.4648769 (119)\ttotal: 10.3s\tremaining: 1m 14s\n",
      "121:\tlearn: 0.4196299\ttest: 0.4649258\tbest: 0.4648769 (119)\ttotal: 10.4s\tremaining: 1m 14s\n",
      "122:\tlearn: 0.4194717\ttest: 0.4649509\tbest: 0.4648769 (119)\ttotal: 10.5s\tremaining: 1m 14s\n",
      "123:\tlearn: 0.4190383\ttest: 0.4649582\tbest: 0.4648769 (119)\ttotal: 10.6s\tremaining: 1m 14s\n",
      "124:\tlearn: 0.4188157\ttest: 0.4651552\tbest: 0.4648769 (119)\ttotal: 10.6s\tremaining: 1m 14s\n",
      "125:\tlearn: 0.4180785\ttest: 0.4647203\tbest: 0.4647203 (125)\ttotal: 10.7s\tremaining: 1m 14s\n",
      "126:\tlearn: 0.4177366\ttest: 0.4648785\tbest: 0.4647203 (125)\ttotal: 10.9s\tremaining: 1m 14s\n",
      "127:\tlearn: 0.4176593\ttest: 0.4648048\tbest: 0.4647203 (125)\ttotal: 10.9s\tremaining: 1m 14s\n",
      "128:\tlearn: 0.4175867\ttest: 0.4647260\tbest: 0.4647203 (125)\ttotal: 11.1s\tremaining: 1m 14s\n",
      "129:\tlearn: 0.4173817\ttest: 0.4647113\tbest: 0.4647113 (129)\ttotal: 11.2s\tremaining: 1m 14s\n",
      "130:\tlearn: 0.4173186\ttest: 0.4647363\tbest: 0.4647113 (129)\ttotal: 11.3s\tremaining: 1m 14s\n",
      "131:\tlearn: 0.4167410\ttest: 0.4648438\tbest: 0.4647113 (129)\ttotal: 11.5s\tremaining: 1m 15s\n",
      "132:\tlearn: 0.4166794\ttest: 0.4649213\tbest: 0.4647113 (129)\ttotal: 11.6s\tremaining: 1m 15s\n",
      "133:\tlearn: 0.4164355\ttest: 0.4649220\tbest: 0.4647113 (129)\ttotal: 11.7s\tremaining: 1m 15s\n",
      "134:\tlearn: 0.4163560\ttest: 0.4647751\tbest: 0.4647113 (129)\ttotal: 11.8s\tremaining: 1m 15s\n",
      "135:\tlearn: 0.4162938\ttest: 0.4647834\tbest: 0.4647113 (129)\ttotal: 11.9s\tremaining: 1m 15s\n",
      "136:\tlearn: 0.4162862\ttest: 0.4647943\tbest: 0.4647113 (129)\ttotal: 12s\tremaining: 1m 15s\n",
      "137:\tlearn: 0.4159094\ttest: 0.4647552\tbest: 0.4647113 (129)\ttotal: 12.1s\tremaining: 1m 15s\n",
      "138:\tlearn: 0.4156480\ttest: 0.4647584\tbest: 0.4647113 (129)\ttotal: 12.2s\tremaining: 1m 15s\n",
      "139:\tlearn: 0.4152140\ttest: 0.4645344\tbest: 0.4645344 (139)\ttotal: 12.3s\tremaining: 1m 15s\n",
      "140:\tlearn: 0.4147901\ttest: 0.4646434\tbest: 0.4645344 (139)\ttotal: 12.4s\tremaining: 1m 15s\n",
      "141:\tlearn: 0.4144135\ttest: 0.4645958\tbest: 0.4645344 (139)\ttotal: 12.6s\tremaining: 1m 15s\n",
      "142:\tlearn: 0.4140332\ttest: 0.4644253\tbest: 0.4644253 (142)\ttotal: 12.7s\tremaining: 1m 16s\n",
      "143:\tlearn: 0.4139207\ttest: 0.4644340\tbest: 0.4644253 (142)\ttotal: 12.9s\tremaining: 1m 16s\n",
      "144:\tlearn: 0.4136888\ttest: 0.4645004\tbest: 0.4644253 (142)\ttotal: 13s\tremaining: 1m 16s\n",
      "145:\tlearn: 0.4135585\ttest: 0.4644299\tbest: 0.4644253 (142)\ttotal: 13.1s\tremaining: 1m 16s\n",
      "146:\tlearn: 0.4132841\ttest: 0.4645437\tbest: 0.4644253 (142)\ttotal: 13.3s\tremaining: 1m 17s\n",
      "147:\tlearn: 0.4132260\ttest: 0.4645124\tbest: 0.4644253 (142)\ttotal: 13.4s\tremaining: 1m 17s\n",
      "148:\tlearn: 0.4128973\ttest: 0.4643091\tbest: 0.4643091 (148)\ttotal: 13.6s\tremaining: 1m 17s\n",
      "149:\tlearn: 0.4124822\ttest: 0.4642188\tbest: 0.4642188 (149)\ttotal: 13.7s\tremaining: 1m 17s\n",
      "150:\tlearn: 0.4122876\ttest: 0.4642696\tbest: 0.4642188 (149)\ttotal: 13.9s\tremaining: 1m 18s\n",
      "151:\tlearn: 0.4122085\ttest: 0.4642806\tbest: 0.4642188 (149)\ttotal: 14s\tremaining: 1m 18s\n",
      "152:\tlearn: 0.4120877\ttest: 0.4643074\tbest: 0.4642188 (149)\ttotal: 14.1s\tremaining: 1m 18s\n",
      "153:\tlearn: 0.4117274\ttest: 0.4643366\tbest: 0.4642188 (149)\ttotal: 14.2s\tremaining: 1m 17s\n",
      "154:\tlearn: 0.4115925\ttest: 0.4644297\tbest: 0.4642188 (149)\ttotal: 14.3s\tremaining: 1m 18s\n",
      "155:\tlearn: 0.4111155\ttest: 0.4642606\tbest: 0.4642188 (149)\ttotal: 14.5s\tremaining: 1m 18s\n",
      "156:\tlearn: 0.4110353\ttest: 0.4642045\tbest: 0.4642045 (156)\ttotal: 14.6s\tremaining: 1m 18s\n",
      "157:\tlearn: 0.4107211\ttest: 0.4643473\tbest: 0.4642045 (156)\ttotal: 14.7s\tremaining: 1m 18s\n",
      "158:\tlearn: 0.4105500\ttest: 0.4640880\tbest: 0.4640880 (158)\ttotal: 14.8s\tremaining: 1m 18s\n",
      "159:\tlearn: 0.4101874\ttest: 0.4639058\tbest: 0.4639058 (159)\ttotal: 15s\tremaining: 1m 18s\n",
      "160:\tlearn: 0.4100243\ttest: 0.4638298\tbest: 0.4638298 (160)\ttotal: 15.1s\tremaining: 1m 18s\n",
      "161:\tlearn: 0.4100116\ttest: 0.4638257\tbest: 0.4638257 (161)\ttotal: 15.2s\tremaining: 1m 18s\n",
      "162:\tlearn: 0.4098525\ttest: 0.4638475\tbest: 0.4638257 (161)\ttotal: 15.3s\tremaining: 1m 18s\n",
      "163:\tlearn: 0.4095251\ttest: 0.4639703\tbest: 0.4638257 (161)\ttotal: 15.4s\tremaining: 1m 18s\n",
      "164:\tlearn: 0.4095074\ttest: 0.4639653\tbest: 0.4638257 (161)\ttotal: 15.5s\tremaining: 1m 18s\n",
      "165:\tlearn: 0.4091816\ttest: 0.4639982\tbest: 0.4638257 (161)\ttotal: 15.6s\tremaining: 1m 18s\n",
      "166:\tlearn: 0.4088317\ttest: 0.4638828\tbest: 0.4638257 (161)\ttotal: 15.7s\tremaining: 1m 18s\n",
      "167:\tlearn: 0.4083408\ttest: 0.4636639\tbest: 0.4636639 (167)\ttotal: 15.8s\tremaining: 1m 18s\n",
      "168:\tlearn: 0.4081999\ttest: 0.4637133\tbest: 0.4636639 (167)\ttotal: 15.9s\tremaining: 1m 18s\n",
      "169:\tlearn: 0.4079050\ttest: 0.4635712\tbest: 0.4635712 (169)\ttotal: 16s\tremaining: 1m 18s\n",
      "170:\tlearn: 0.4078067\ttest: 0.4636039\tbest: 0.4635712 (169)\ttotal: 16.1s\tremaining: 1m 17s\n",
      "171:\tlearn: 0.4074701\ttest: 0.4635245\tbest: 0.4635245 (171)\ttotal: 16.2s\tremaining: 1m 17s\n",
      "172:\tlearn: 0.4070694\ttest: 0.4636017\tbest: 0.4635245 (171)\ttotal: 16.3s\tremaining: 1m 17s\n",
      "173:\tlearn: 0.4069042\ttest: 0.4636744\tbest: 0.4635245 (171)\ttotal: 16.4s\tremaining: 1m 17s\n",
      "174:\tlearn: 0.4066251\ttest: 0.4637413\tbest: 0.4635245 (171)\ttotal: 16.5s\tremaining: 1m 17s\n",
      "175:\tlearn: 0.4065616\ttest: 0.4638027\tbest: 0.4635245 (171)\ttotal: 16.6s\tremaining: 1m 17s\n",
      "176:\tlearn: 0.4064226\ttest: 0.4638338\tbest: 0.4635245 (171)\ttotal: 16.8s\tremaining: 1m 18s\n",
      "177:\tlearn: 0.4060009\ttest: 0.4640203\tbest: 0.4635245 (171)\ttotal: 17s\tremaining: 1m 18s\n",
      "178:\tlearn: 0.4055316\ttest: 0.4638281\tbest: 0.4635245 (171)\ttotal: 17.1s\tremaining: 1m 18s\n",
      "179:\tlearn: 0.4053555\ttest: 0.4637873\tbest: 0.4635245 (171)\ttotal: 17.3s\tremaining: 1m 18s\n",
      "180:\tlearn: 0.4053365\ttest: 0.4637549\tbest: 0.4635245 (171)\ttotal: 17.4s\tremaining: 1m 18s\n",
      "181:\tlearn: 0.4052545\ttest: 0.4637474\tbest: 0.4635245 (171)\ttotal: 17.5s\tremaining: 1m 18s\n",
      "182:\tlearn: 0.4052381\ttest: 0.4637577\tbest: 0.4635245 (171)\ttotal: 17.6s\tremaining: 1m 18s\n",
      "183:\tlearn: 0.4049261\ttest: 0.4635392\tbest: 0.4635245 (171)\ttotal: 17.7s\tremaining: 1m 18s\n",
      "184:\tlearn: 0.4047527\ttest: 0.4634177\tbest: 0.4634177 (184)\ttotal: 17.8s\tremaining: 1m 18s\n",
      "185:\tlearn: 0.4047358\ttest: 0.4634340\tbest: 0.4634177 (184)\ttotal: 17.9s\tremaining: 1m 18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186:\tlearn: 0.4045692\ttest: 0.4634698\tbest: 0.4634177 (184)\ttotal: 18s\tremaining: 1m 18s\n",
      "187:\tlearn: 0.4045339\ttest: 0.4634957\tbest: 0.4634177 (184)\ttotal: 18.1s\tremaining: 1m 18s\n",
      "188:\tlearn: 0.4044866\ttest: 0.4635052\tbest: 0.4634177 (184)\ttotal: 18.2s\tremaining: 1m 18s\n",
      "189:\tlearn: 0.4042885\ttest: 0.4634322\tbest: 0.4634177 (184)\ttotal: 18.3s\tremaining: 1m 18s\n",
      "190:\tlearn: 0.4039486\ttest: 0.4634606\tbest: 0.4634177 (184)\ttotal: 18.4s\tremaining: 1m 17s\n",
      "191:\tlearn: 0.4038063\ttest: 0.4634748\tbest: 0.4634177 (184)\ttotal: 18.5s\tremaining: 1m 17s\n",
      "192:\tlearn: 0.4033085\ttest: 0.4634437\tbest: 0.4634177 (184)\ttotal: 18.6s\tremaining: 1m 17s\n",
      "193:\tlearn: 0.4029899\ttest: 0.4633095\tbest: 0.4633095 (193)\ttotal: 18.7s\tremaining: 1m 17s\n",
      "194:\tlearn: 0.4027073\ttest: 0.4632842\tbest: 0.4632842 (194)\ttotal: 18.8s\tremaining: 1m 17s\n",
      "195:\tlearn: 0.4026663\ttest: 0.4632935\tbest: 0.4632842 (194)\ttotal: 18.9s\tremaining: 1m 17s\n",
      "196:\tlearn: 0.4024444\ttest: 0.4632560\tbest: 0.4632560 (196)\ttotal: 19s\tremaining: 1m 17s\n",
      "197:\tlearn: 0.4023445\ttest: 0.4631569\tbest: 0.4631569 (197)\ttotal: 19.1s\tremaining: 1m 17s\n",
      "198:\tlearn: 0.4023377\ttest: 0.4631772\tbest: 0.4631569 (197)\ttotal: 19.2s\tremaining: 1m 17s\n",
      "199:\tlearn: 0.4022686\ttest: 0.4631590\tbest: 0.4631569 (197)\ttotal: 19.2s\tremaining: 1m 16s\n",
      "200:\tlearn: 0.4022624\ttest: 0.4631809\tbest: 0.4631569 (197)\ttotal: 19.3s\tremaining: 1m 16s\n",
      "201:\tlearn: 0.4022227\ttest: 0.4631676\tbest: 0.4631569 (197)\ttotal: 19.4s\tremaining: 1m 16s\n",
      "202:\tlearn: 0.4018126\ttest: 0.4630918\tbest: 0.4630918 (202)\ttotal: 19.5s\tremaining: 1m 16s\n",
      "203:\tlearn: 0.4017286\ttest: 0.4630044\tbest: 0.4630044 (203)\ttotal: 19.6s\tremaining: 1m 16s\n",
      "204:\tlearn: 0.4015861\ttest: 0.4630424\tbest: 0.4630044 (203)\ttotal: 19.7s\tremaining: 1m 16s\n",
      "205:\tlearn: 0.4015813\ttest: 0.4630524\tbest: 0.4630044 (203)\ttotal: 19.8s\tremaining: 1m 16s\n",
      "206:\tlearn: 0.4014459\ttest: 0.4630137\tbest: 0.4630044 (203)\ttotal: 19.9s\tremaining: 1m 16s\n",
      "207:\tlearn: 0.4012290\ttest: 0.4629341\tbest: 0.4629341 (207)\ttotal: 20s\tremaining: 1m 16s\n",
      "208:\tlearn: 0.4010134\ttest: 0.4630937\tbest: 0.4629341 (207)\ttotal: 20.1s\tremaining: 1m 16s\n",
      "209:\tlearn: 0.4006098\ttest: 0.4629770\tbest: 0.4629341 (207)\ttotal: 20.2s\tremaining: 1m 16s\n",
      "210:\tlearn: 0.4000750\ttest: 0.4629457\tbest: 0.4629341 (207)\ttotal: 20.3s\tremaining: 1m 16s\n",
      "211:\tlearn: 0.3998371\ttest: 0.4629062\tbest: 0.4629062 (211)\ttotal: 20.4s\tremaining: 1m 15s\n",
      "212:\tlearn: 0.3998292\ttest: 0.4629130\tbest: 0.4629062 (211)\ttotal: 20.5s\tremaining: 1m 15s\n",
      "213:\tlearn: 0.3997279\ttest: 0.4629140\tbest: 0.4629062 (211)\ttotal: 20.6s\tremaining: 1m 15s\n",
      "214:\tlearn: 0.3995338\ttest: 0.4629631\tbest: 0.4629062 (211)\ttotal: 20.7s\tremaining: 1m 15s\n",
      "215:\tlearn: 0.3995266\ttest: 0.4629780\tbest: 0.4629062 (211)\ttotal: 20.8s\tremaining: 1m 15s\n",
      "216:\tlearn: 0.3992668\ttest: 0.4631967\tbest: 0.4629062 (211)\ttotal: 20.9s\tremaining: 1m 15s\n",
      "217:\tlearn: 0.3991504\ttest: 0.4631955\tbest: 0.4629062 (211)\ttotal: 21s\tremaining: 1m 15s\n",
      "218:\tlearn: 0.3989813\ttest: 0.4630864\tbest: 0.4629062 (211)\ttotal: 21.1s\tremaining: 1m 15s\n",
      "219:\tlearn: 0.3989023\ttest: 0.4630589\tbest: 0.4629062 (211)\ttotal: 21.2s\tremaining: 1m 15s\n",
      "220:\tlearn: 0.3987288\ttest: 0.4630304\tbest: 0.4629062 (211)\ttotal: 21.3s\tremaining: 1m 15s\n",
      "221:\tlearn: 0.3986129\ttest: 0.4632547\tbest: 0.4629062 (211)\ttotal: 21.4s\tremaining: 1m 15s\n",
      "222:\tlearn: 0.3985200\ttest: 0.4632751\tbest: 0.4629062 (211)\ttotal: 21.5s\tremaining: 1m 14s\n",
      "223:\tlearn: 0.3984777\ttest: 0.4631781\tbest: 0.4629062 (211)\ttotal: 21.6s\tremaining: 1m 14s\n",
      "224:\tlearn: 0.3981295\ttest: 0.4632967\tbest: 0.4629062 (211)\ttotal: 21.7s\tremaining: 1m 14s\n",
      "225:\tlearn: 0.3981251\ttest: 0.4632929\tbest: 0.4629062 (211)\ttotal: 21.8s\tremaining: 1m 14s\n",
      "226:\tlearn: 0.3980438\ttest: 0.4632036\tbest: 0.4629062 (211)\ttotal: 21.9s\tremaining: 1m 14s\n",
      "227:\tlearn: 0.3980361\ttest: 0.4632020\tbest: 0.4629062 (211)\ttotal: 22s\tremaining: 1m 14s\n",
      "228:\tlearn: 0.3980311\ttest: 0.4632030\tbest: 0.4629062 (211)\ttotal: 22.1s\tremaining: 1m 14s\n",
      "229:\tlearn: 0.3976435\ttest: 0.4633735\tbest: 0.4629062 (211)\ttotal: 22.2s\tremaining: 1m 14s\n",
      "230:\tlearn: 0.3975849\ttest: 0.4633120\tbest: 0.4629062 (211)\ttotal: 22.2s\tremaining: 1m 14s\n",
      "231:\tlearn: 0.3975183\ttest: 0.4632999\tbest: 0.4629062 (211)\ttotal: 22.4s\tremaining: 1m 14s\n",
      "232:\tlearn: 0.3973430\ttest: 0.4633383\tbest: 0.4629062 (211)\ttotal: 22.4s\tremaining: 1m 13s\n",
      "233:\tlearn: 0.3972273\ttest: 0.4633371\tbest: 0.4629062 (211)\ttotal: 22.5s\tremaining: 1m 13s\n",
      "234:\tlearn: 0.3967963\ttest: 0.4631708\tbest: 0.4629062 (211)\ttotal: 22.6s\tremaining: 1m 13s\n",
      "235:\tlearn: 0.3967186\ttest: 0.4631419\tbest: 0.4629062 (211)\ttotal: 22.7s\tremaining: 1m 13s\n",
      "236:\tlearn: 0.3967091\ttest: 0.4631463\tbest: 0.4629062 (211)\ttotal: 22.9s\tremaining: 1m 13s\n",
      "237:\tlearn: 0.3963506\ttest: 0.4631869\tbest: 0.4629062 (211)\ttotal: 23s\tremaining: 1m 13s\n",
      "238:\tlearn: 0.3960228\ttest: 0.4631557\tbest: 0.4629062 (211)\ttotal: 23.1s\tremaining: 1m 13s\n",
      "239:\tlearn: 0.3959888\ttest: 0.4631717\tbest: 0.4629062 (211)\ttotal: 23.2s\tremaining: 1m 13s\n",
      "240:\tlearn: 0.3957301\ttest: 0.4631968\tbest: 0.4629062 (211)\ttotal: 23.3s\tremaining: 1m 13s\n",
      "241:\tlearn: 0.3957074\ttest: 0.4631899\tbest: 0.4629062 (211)\ttotal: 23.4s\tremaining: 1m 13s\n",
      "242:\tlearn: 0.3956166\ttest: 0.4631260\tbest: 0.4629062 (211)\ttotal: 23.5s\tremaining: 1m 13s\n",
      "243:\tlearn: 0.3954038\ttest: 0.4630973\tbest: 0.4629062 (211)\ttotal: 23.6s\tremaining: 1m 13s\n",
      "244:\tlearn: 0.3953270\ttest: 0.4631450\tbest: 0.4629062 (211)\ttotal: 23.7s\tremaining: 1m 12s\n",
      "245:\tlearn: 0.3947553\ttest: 0.4633004\tbest: 0.4629062 (211)\ttotal: 23.7s\tremaining: 1m 12s\n",
      "246:\tlearn: 0.3947235\ttest: 0.4632308\tbest: 0.4629062 (211)\ttotal: 23.9s\tremaining: 1m 12s\n",
      "247:\tlearn: 0.3946011\ttest: 0.4633314\tbest: 0.4629062 (211)\ttotal: 23.9s\tremaining: 1m 12s\n",
      "248:\tlearn: 0.3944284\ttest: 0.4633458\tbest: 0.4629062 (211)\ttotal: 24.1s\tremaining: 1m 12s\n",
      "249:\tlearn: 0.3943564\ttest: 0.4633018\tbest: 0.4629062 (211)\ttotal: 24.1s\tremaining: 1m 12s\n",
      "250:\tlearn: 0.3940442\ttest: 0.4633943\tbest: 0.4629062 (211)\ttotal: 24.2s\tremaining: 1m 12s\n",
      "251:\tlearn: 0.3940172\ttest: 0.4634077\tbest: 0.4629062 (211)\ttotal: 24.3s\tremaining: 1m 12s\n",
      "252:\tlearn: 0.3939925\ttest: 0.4634045\tbest: 0.4629062 (211)\ttotal: 24.4s\tremaining: 1m 12s\n",
      "253:\tlearn: 0.3937947\ttest: 0.4634316\tbest: 0.4629062 (211)\ttotal: 24.5s\tremaining: 1m 11s\n",
      "254:\tlearn: 0.3936404\ttest: 0.4634361\tbest: 0.4629062 (211)\ttotal: 24.6s\tremaining: 1m 11s\n",
      "255:\tlearn: 0.3935843\ttest: 0.4633728\tbest: 0.4629062 (211)\ttotal: 24.7s\tremaining: 1m 11s\n",
      "256:\tlearn: 0.3933914\ttest: 0.4634700\tbest: 0.4629062 (211)\ttotal: 24.8s\tremaining: 1m 11s\n",
      "257:\tlearn: 0.3930943\ttest: 0.4635367\tbest: 0.4629062 (211)\ttotal: 24.9s\tremaining: 1m 11s\n",
      "258:\tlearn: 0.3928686\ttest: 0.4637483\tbest: 0.4629062 (211)\ttotal: 25s\tremaining: 1m 11s\n",
      "259:\tlearn: 0.3928368\ttest: 0.4637429\tbest: 0.4629062 (211)\ttotal: 25.1s\tremaining: 1m 11s\n",
      "260:\tlearn: 0.3926549\ttest: 0.4637153\tbest: 0.4629062 (211)\ttotal: 25.2s\tremaining: 1m 11s\n",
      "261:\tlearn: 0.3924540\ttest: 0.4635441\tbest: 0.4629062 (211)\ttotal: 25.3s\tremaining: 1m 11s\n",
      "262:\tlearn: 0.3923736\ttest: 0.4634587\tbest: 0.4629062 (211)\ttotal: 25.4s\tremaining: 1m 11s\n",
      "263:\tlearn: 0.3923522\ttest: 0.4634659\tbest: 0.4629062 (211)\ttotal: 25.4s\tremaining: 1m 10s\n",
      "264:\tlearn: 0.3921576\ttest: 0.4636239\tbest: 0.4629062 (211)\ttotal: 25.6s\tremaining: 1m 10s\n",
      "265:\tlearn: 0.3920711\ttest: 0.4635478\tbest: 0.4629062 (211)\ttotal: 25.7s\tremaining: 1m 10s\n",
      "266:\tlearn: 0.3919073\ttest: 0.4634025\tbest: 0.4629062 (211)\ttotal: 25.8s\tremaining: 1m 10s\n",
      "267:\tlearn: 0.3919057\ttest: 0.4634022\tbest: 0.4629062 (211)\ttotal: 25.9s\tremaining: 1m 10s\n",
      "268:\tlearn: 0.3916415\ttest: 0.4631193\tbest: 0.4629062 (211)\ttotal: 26s\tremaining: 1m 10s\n",
      "269:\tlearn: 0.3916400\ttest: 0.4631182\tbest: 0.4629062 (211)\ttotal: 26.1s\tremaining: 1m 10s\n",
      "270:\tlearn: 0.3913354\ttest: 0.4631586\tbest: 0.4629062 (211)\ttotal: 26.2s\tremaining: 1m 10s\n",
      "271:\tlearn: 0.3910932\ttest: 0.4633662\tbest: 0.4629062 (211)\ttotal: 26.3s\tremaining: 1m 10s\n",
      "272:\tlearn: 0.3910504\ttest: 0.4633408\tbest: 0.4629062 (211)\ttotal: 26.4s\tremaining: 1m 10s\n",
      "273:\tlearn: 0.3910327\ttest: 0.4633276\tbest: 0.4629062 (211)\ttotal: 26.5s\tremaining: 1m 10s\n",
      "274:\tlearn: 0.3909731\ttest: 0.4632703\tbest: 0.4629062 (211)\ttotal: 26.6s\tremaining: 1m 10s\n",
      "275:\tlearn: 0.3909662\ttest: 0.4632742\tbest: 0.4629062 (211)\ttotal: 26.7s\tremaining: 1m 9s\n",
      "276:\tlearn: 0.3908381\ttest: 0.4632141\tbest: 0.4629062 (211)\ttotal: 26.8s\tremaining: 1m 9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277:\tlearn: 0.3906584\ttest: 0.4632028\tbest: 0.4629062 (211)\ttotal: 26.9s\tremaining: 1m 9s\n",
      "278:\tlearn: 0.3905626\ttest: 0.4632013\tbest: 0.4629062 (211)\ttotal: 26.9s\tremaining: 1m 9s\n",
      "279:\tlearn: 0.3905393\ttest: 0.4632086\tbest: 0.4629062 (211)\ttotal: 27s\tremaining: 1m 9s\n",
      "280:\tlearn: 0.3903794\ttest: 0.4633500\tbest: 0.4629062 (211)\ttotal: 27.1s\tremaining: 1m 9s\n",
      "281:\tlearn: 0.3903294\ttest: 0.4633768\tbest: 0.4629062 (211)\ttotal: 27.2s\tremaining: 1m 9s\n",
      "282:\tlearn: 0.3900686\ttest: 0.4633793\tbest: 0.4629062 (211)\ttotal: 27.3s\tremaining: 1m 9s\n",
      "283:\tlearn: 0.3900684\ttest: 0.4633850\tbest: 0.4629062 (211)\ttotal: 27.4s\tremaining: 1m 8s\n",
      "284:\tlearn: 0.3899141\ttest: 0.4635226\tbest: 0.4629062 (211)\ttotal: 27.5s\tremaining: 1m 8s\n",
      "285:\tlearn: 0.3897886\ttest: 0.4633885\tbest: 0.4629062 (211)\ttotal: 27.6s\tremaining: 1m 8s\n",
      "286:\tlearn: 0.3897878\ttest: 0.4633939\tbest: 0.4629062 (211)\ttotal: 27.7s\tremaining: 1m 8s\n",
      "287:\tlearn: 0.3896206\ttest: 0.4635339\tbest: 0.4629062 (211)\ttotal: 27.8s\tremaining: 1m 8s\n",
      "288:\tlearn: 0.3896045\ttest: 0.4635178\tbest: 0.4629062 (211)\ttotal: 27.9s\tremaining: 1m 8s\n",
      "289:\tlearn: 0.3894580\ttest: 0.4634586\tbest: 0.4629062 (211)\ttotal: 27.9s\tremaining: 1m 8s\n",
      "290:\tlearn: 0.3894006\ttest: 0.4634134\tbest: 0.4629062 (211)\ttotal: 28s\tremaining: 1m 8s\n",
      "291:\tlearn: 0.3893985\ttest: 0.4634131\tbest: 0.4629062 (211)\ttotal: 28.1s\tremaining: 1m 8s\n",
      "292:\tlearn: 0.3893791\ttest: 0.4634195\tbest: 0.4629062 (211)\ttotal: 28.2s\tremaining: 1m 8s\n",
      "293:\tlearn: 0.3893254\ttest: 0.4634317\tbest: 0.4629062 (211)\ttotal: 28.3s\tremaining: 1m 7s\n",
      "294:\tlearn: 0.3891900\ttest: 0.4635553\tbest: 0.4629062 (211)\ttotal: 28.4s\tremaining: 1m 7s\n",
      "295:\tlearn: 0.3891898\ttest: 0.4635611\tbest: 0.4629062 (211)\ttotal: 28.5s\tremaining: 1m 7s\n",
      "296:\tlearn: 0.3890081\ttest: 0.4634197\tbest: 0.4629062 (211)\ttotal: 28.6s\tremaining: 1m 7s\n",
      "297:\tlearn: 0.3888842\ttest: 0.4633570\tbest: 0.4629062 (211)\ttotal: 28.6s\tremaining: 1m 7s\n",
      "298:\tlearn: 0.3888394\ttest: 0.4633452\tbest: 0.4629062 (211)\ttotal: 28.7s\tremaining: 1m 7s\n",
      "299:\tlearn: 0.3887438\ttest: 0.4633749\tbest: 0.4629062 (211)\ttotal: 28.8s\tremaining: 1m 7s\n",
      "300:\tlearn: 0.3887197\ttest: 0.4633764\tbest: 0.4629062 (211)\ttotal: 28.9s\tremaining: 1m 7s\n",
      "301:\tlearn: 0.3887178\ttest: 0.4633763\tbest: 0.4629062 (211)\ttotal: 29s\tremaining: 1m 7s\n",
      "302:\tlearn: 0.3886600\ttest: 0.4633773\tbest: 0.4629062 (211)\ttotal: 29.1s\tremaining: 1m 6s\n",
      "303:\tlearn: 0.3885469\ttest: 0.4633219\tbest: 0.4629062 (211)\ttotal: 29.2s\tremaining: 1m 6s\n",
      "304:\tlearn: 0.3884778\ttest: 0.4632562\tbest: 0.4629062 (211)\ttotal: 29.3s\tremaining: 1m 6s\n",
      "305:\tlearn: 0.3884721\ttest: 0.4632626\tbest: 0.4629062 (211)\ttotal: 29.4s\tremaining: 1m 6s\n",
      "306:\tlearn: 0.3884512\ttest: 0.4632796\tbest: 0.4629062 (211)\ttotal: 29.4s\tremaining: 1m 6s\n",
      "307:\tlearn: 0.3884307\ttest: 0.4632988\tbest: 0.4629062 (211)\ttotal: 29.5s\tremaining: 1m 6s\n",
      "308:\tlearn: 0.3884161\ttest: 0.4632715\tbest: 0.4629062 (211)\ttotal: 29.6s\tremaining: 1m 6s\n",
      "309:\tlearn: 0.3879070\ttest: 0.4633810\tbest: 0.4629062 (211)\ttotal: 29.7s\tremaining: 1m 6s\n",
      "310:\tlearn: 0.3876923\ttest: 0.4635019\tbest: 0.4629062 (211)\ttotal: 29.8s\tremaining: 1m 6s\n",
      "311:\tlearn: 0.3876586\ttest: 0.4634805\tbest: 0.4629062 (211)\ttotal: 29.9s\tremaining: 1m 5s\n",
      "312:\tlearn: 0.3873488\ttest: 0.4632704\tbest: 0.4629062 (211)\ttotal: 30s\tremaining: 1m 5s\n",
      "313:\tlearn: 0.3872984\ttest: 0.4633269\tbest: 0.4629062 (211)\ttotal: 30.1s\tremaining: 1m 5s\n",
      "314:\tlearn: 0.3872622\ttest: 0.4633514\tbest: 0.4629062 (211)\ttotal: 30.2s\tremaining: 1m 5s\n",
      "315:\tlearn: 0.3872621\ttest: 0.4633575\tbest: 0.4629062 (211)\ttotal: 30.2s\tremaining: 1m 5s\n",
      "316:\tlearn: 0.3872619\ttest: 0.4633636\tbest: 0.4629062 (211)\ttotal: 30.3s\tremaining: 1m 5s\n",
      "317:\tlearn: 0.3872618\ttest: 0.4633698\tbest: 0.4629062 (211)\ttotal: 30.3s\tremaining: 1m 4s\n",
      "318:\tlearn: 0.3872596\ttest: 0.4633693\tbest: 0.4629062 (211)\ttotal: 30.3s\tremaining: 1m 4s\n",
      "319:\tlearn: 0.3872518\ttest: 0.4633603\tbest: 0.4629062 (211)\ttotal: 30.4s\tremaining: 1m 4s\n",
      "320:\tlearn: 0.3872343\ttest: 0.4633655\tbest: 0.4629062 (211)\ttotal: 30.5s\tremaining: 1m 4s\n",
      "321:\tlearn: 0.3871518\ttest: 0.4633449\tbest: 0.4629062 (211)\ttotal: 30.6s\tremaining: 1m 4s\n",
      "322:\tlearn: 0.3871502\ttest: 0.4633448\tbest: 0.4629062 (211)\ttotal: 30.6s\tremaining: 1m 4s\n",
      "323:\tlearn: 0.3871485\ttest: 0.4633495\tbest: 0.4629062 (211)\ttotal: 30.7s\tremaining: 1m 4s\n",
      "324:\tlearn: 0.3870725\ttest: 0.4634207\tbest: 0.4629062 (211)\ttotal: 30.8s\tremaining: 1m 3s\n",
      "325:\tlearn: 0.3870715\ttest: 0.4634210\tbest: 0.4629062 (211)\ttotal: 30.8s\tremaining: 1m 3s\n",
      "326:\tlearn: 0.3870169\ttest: 0.4633903\tbest: 0.4629062 (211)\ttotal: 30.9s\tremaining: 1m 3s\n",
      "327:\tlearn: 0.3869569\ttest: 0.4634397\tbest: 0.4629062 (211)\ttotal: 31s\tremaining: 1m 3s\n",
      "328:\tlearn: 0.3869561\ttest: 0.4634399\tbest: 0.4629062 (211)\ttotal: 31.1s\tremaining: 1m 3s\n",
      "329:\tlearn: 0.3865437\ttest: 0.4635530\tbest: 0.4629062 (211)\ttotal: 31.1s\tremaining: 1m 3s\n",
      "330:\tlearn: 0.3863185\ttest: 0.4635608\tbest: 0.4629062 (211)\ttotal: 31.2s\tremaining: 1m 3s\n",
      "331:\tlearn: 0.3862720\ttest: 0.4635247\tbest: 0.4629062 (211)\ttotal: 31.3s\tremaining: 1m 3s\n",
      "332:\tlearn: 0.3862494\ttest: 0.4635194\tbest: 0.4629062 (211)\ttotal: 31.4s\tremaining: 1m 2s\n",
      "333:\tlearn: 0.3861869\ttest: 0.4634609\tbest: 0.4629062 (211)\ttotal: 31.6s\tremaining: 1m 2s\n",
      "334:\tlearn: 0.3861866\ttest: 0.4634669\tbest: 0.4629062 (211)\ttotal: 31.6s\tremaining: 1m 2s\n",
      "335:\tlearn: 0.3861254\ttest: 0.4634948\tbest: 0.4629062 (211)\ttotal: 31.7s\tremaining: 1m 2s\n",
      "336:\tlearn: 0.3858944\ttest: 0.4634513\tbest: 0.4629062 (211)\ttotal: 31.9s\tremaining: 1m 2s\n",
      "337:\tlearn: 0.3856987\ttest: 0.4634454\tbest: 0.4629062 (211)\ttotal: 31.9s\tremaining: 1m 2s\n",
      "338:\tlearn: 0.3856983\ttest: 0.4634465\tbest: 0.4629062 (211)\ttotal: 32s\tremaining: 1m 2s\n",
      "339:\tlearn: 0.3856887\ttest: 0.4634694\tbest: 0.4629062 (211)\ttotal: 32.2s\tremaining: 1m 2s\n",
      "340:\tlearn: 0.3856158\ttest: 0.4634748\tbest: 0.4629062 (211)\ttotal: 32.3s\tremaining: 1m 2s\n",
      "341:\tlearn: 0.3853200\ttest: 0.4633971\tbest: 0.4629062 (211)\ttotal: 32.4s\tremaining: 1m 2s\n",
      "342:\tlearn: 0.3852754\ttest: 0.4633561\tbest: 0.4629062 (211)\ttotal: 32.4s\tremaining: 1m 2s\n",
      "343:\tlearn: 0.3852194\ttest: 0.4634273\tbest: 0.4629062 (211)\ttotal: 32.5s\tremaining: 1m 2s\n",
      "344:\tlearn: 0.3850295\ttest: 0.4635671\tbest: 0.4629062 (211)\ttotal: 32.6s\tremaining: 1m 1s\n",
      "345:\tlearn: 0.3848005\ttest: 0.4635955\tbest: 0.4629062 (211)\ttotal: 32.7s\tremaining: 1m 1s\n",
      "346:\tlearn: 0.3847944\ttest: 0.4636073\tbest: 0.4629062 (211)\ttotal: 32.8s\tremaining: 1m 1s\n",
      "347:\tlearn: 0.3846857\ttest: 0.4636262\tbest: 0.4629062 (211)\ttotal: 32.9s\tremaining: 1m 1s\n",
      "348:\tlearn: 0.3846833\ttest: 0.4636266\tbest: 0.4629062 (211)\ttotal: 33s\tremaining: 1m 1s\n",
      "349:\tlearn: 0.3846363\ttest: 0.4636306\tbest: 0.4629062 (211)\ttotal: 33.1s\tremaining: 1m 1s\n",
      "350:\tlearn: 0.3845530\ttest: 0.4635917\tbest: 0.4629062 (211)\ttotal: 33.3s\tremaining: 1m 1s\n",
      "351:\tlearn: 0.3843939\ttest: 0.4637057\tbest: 0.4629062 (211)\ttotal: 33.4s\tremaining: 1m 1s\n",
      "352:\tlearn: 0.3843681\ttest: 0.4637629\tbest: 0.4629062 (211)\ttotal: 33.5s\tremaining: 1m 1s\n",
      "353:\tlearn: 0.3843666\ttest: 0.4637618\tbest: 0.4629062 (211)\ttotal: 33.6s\tremaining: 1m 1s\n",
      "354:\tlearn: 0.3843305\ttest: 0.4637449\tbest: 0.4629062 (211)\ttotal: 33.7s\tremaining: 1m 1s\n",
      "355:\tlearn: 0.3843148\ttest: 0.4637468\tbest: 0.4629062 (211)\ttotal: 33.8s\tremaining: 1m 1s\n",
      "356:\tlearn: 0.3842164\ttest: 0.4637905\tbest: 0.4629062 (211)\ttotal: 33.9s\tremaining: 1m 1s\n",
      "357:\tlearn: 0.3839904\ttest: 0.4637075\tbest: 0.4629062 (211)\ttotal: 34s\tremaining: 1m\n",
      "358:\tlearn: 0.3838551\ttest: 0.4637435\tbest: 0.4629062 (211)\ttotal: 34.1s\tremaining: 1m\n",
      "359:\tlearn: 0.3838548\ttest: 0.4637428\tbest: 0.4629062 (211)\ttotal: 34.1s\tremaining: 1m\n",
      "360:\tlearn: 0.3838518\ttest: 0.4637452\tbest: 0.4629062 (211)\ttotal: 34.3s\tremaining: 1m\n",
      "361:\tlearn: 0.3838508\ttest: 0.4637462\tbest: 0.4629062 (211)\ttotal: 34.4s\tremaining: 1m\n",
      "362:\tlearn: 0.3838497\ttest: 0.4637482\tbest: 0.4629062 (211)\ttotal: 34.5s\tremaining: 1m\n",
      "363:\tlearn: 0.3836253\ttest: 0.4640254\tbest: 0.4629062 (211)\ttotal: 34.7s\tremaining: 1m\n",
      "364:\tlearn: 0.3835524\ttest: 0.4639664\tbest: 0.4629062 (211)\ttotal: 34.8s\tremaining: 1m\n",
      "365:\tlearn: 0.3835512\ttest: 0.4639665\tbest: 0.4629062 (211)\ttotal: 35s\tremaining: 1m\n",
      "366:\tlearn: 0.3834186\ttest: 0.4637799\tbest: 0.4629062 (211)\ttotal: 35.1s\tremaining: 1m\n",
      "367:\tlearn: 0.3834177\ttest: 0.4637812\tbest: 0.4629062 (211)\ttotal: 35.2s\tremaining: 1m\n",
      "368:\tlearn: 0.3830197\ttest: 0.4635942\tbest: 0.4629062 (211)\ttotal: 35.4s\tremaining: 1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369:\tlearn: 0.3829627\ttest: 0.4634973\tbest: 0.4629062 (211)\ttotal: 35.5s\tremaining: 1m\n",
      "370:\tlearn: 0.3829597\ttest: 0.4634993\tbest: 0.4629062 (211)\ttotal: 35.7s\tremaining: 1m\n",
      "371:\tlearn: 0.3829364\ttest: 0.4634931\tbest: 0.4629062 (211)\ttotal: 35.8s\tremaining: 1m\n",
      "372:\tlearn: 0.3828350\ttest: 0.4634218\tbest: 0.4629062 (211)\ttotal: 35.9s\tremaining: 1m\n",
      "373:\tlearn: 0.3828330\ttest: 0.4634336\tbest: 0.4629062 (211)\ttotal: 36s\tremaining: 1m\n",
      "374:\tlearn: 0.3826389\ttest: 0.4635189\tbest: 0.4629062 (211)\ttotal: 36.1s\tremaining: 1m\n",
      "375:\tlearn: 0.3826125\ttest: 0.4635716\tbest: 0.4629062 (211)\ttotal: 36.2s\tremaining: 1m\n",
      "376:\tlearn: 0.3824952\ttest: 0.4636016\tbest: 0.4629062 (211)\ttotal: 36.3s\tremaining: 1m\n",
      "377:\tlearn: 0.3824699\ttest: 0.4635853\tbest: 0.4629062 (211)\ttotal: 36.4s\tremaining: 59.9s\n",
      "378:\tlearn: 0.3822440\ttest: 0.4633492\tbest: 0.4629062 (211)\ttotal: 36.6s\tremaining: 59.9s\n",
      "379:\tlearn: 0.3822334\ttest: 0.4633529\tbest: 0.4629062 (211)\ttotal: 36.7s\tremaining: 59.9s\n",
      "380:\tlearn: 0.3819665\ttest: 0.4632213\tbest: 0.4629062 (211)\ttotal: 36.8s\tremaining: 59.8s\n",
      "381:\tlearn: 0.3819616\ttest: 0.4632118\tbest: 0.4629062 (211)\ttotal: 36.9s\tremaining: 59.6s\n",
      "382:\tlearn: 0.3819607\ttest: 0.4632126\tbest: 0.4629062 (211)\ttotal: 37s\tremaining: 59.6s\n",
      "383:\tlearn: 0.3818649\ttest: 0.4631978\tbest: 0.4629062 (211)\ttotal: 37.1s\tremaining: 59.5s\n",
      "384:\tlearn: 0.3818643\ttest: 0.4631992\tbest: 0.4629062 (211)\ttotal: 37.2s\tremaining: 59.4s\n",
      "385:\tlearn: 0.3817409\ttest: 0.4632757\tbest: 0.4629062 (211)\ttotal: 37.3s\tremaining: 59.4s\n",
      "386:\tlearn: 0.3816401\ttest: 0.4633110\tbest: 0.4629062 (211)\ttotal: 37.4s\tremaining: 59.3s\n",
      "387:\tlearn: 0.3814169\ttest: 0.4632774\tbest: 0.4629062 (211)\ttotal: 37.6s\tremaining: 59.3s\n",
      "388:\tlearn: 0.3812900\ttest: 0.4632900\tbest: 0.4629062 (211)\ttotal: 37.7s\tremaining: 59.2s\n",
      "389:\tlearn: 0.3811032\ttest: 0.4634101\tbest: 0.4629062 (211)\ttotal: 37.8s\tremaining: 59.1s\n",
      "390:\tlearn: 0.3810869\ttest: 0.4634745\tbest: 0.4629062 (211)\ttotal: 38s\tremaining: 59.1s\n",
      "391:\tlearn: 0.3810828\ttest: 0.4634771\tbest: 0.4629062 (211)\ttotal: 38.1s\tremaining: 59.1s\n",
      "392:\tlearn: 0.3810687\ttest: 0.4634787\tbest: 0.4629062 (211)\ttotal: 38.2s\tremaining: 59s\n",
      "393:\tlearn: 0.3809858\ttest: 0.4635262\tbest: 0.4629062 (211)\ttotal: 38.3s\tremaining: 58.9s\n",
      "394:\tlearn: 0.3808617\ttest: 0.4634633\tbest: 0.4629062 (211)\ttotal: 38.5s\tremaining: 58.9s\n",
      "395:\tlearn: 0.3806695\ttest: 0.4634853\tbest: 0.4629062 (211)\ttotal: 38.6s\tremaining: 58.8s\n",
      "396:\tlearn: 0.3804019\ttest: 0.4635248\tbest: 0.4629062 (211)\ttotal: 38.7s\tremaining: 58.7s\n",
      "397:\tlearn: 0.3803258\ttest: 0.4634662\tbest: 0.4629062 (211)\ttotal: 38.8s\tremaining: 58.7s\n",
      "398:\tlearn: 0.3800701\ttest: 0.4634674\tbest: 0.4629062 (211)\ttotal: 38.9s\tremaining: 58.6s\n",
      "399:\tlearn: 0.3800683\ttest: 0.4634671\tbest: 0.4629062 (211)\ttotal: 38.9s\tremaining: 58.4s\n",
      "400:\tlearn: 0.3798974\ttest: 0.4637239\tbest: 0.4629062 (211)\ttotal: 39s\tremaining: 58.3s\n",
      "401:\tlearn: 0.3798448\ttest: 0.4637240\tbest: 0.4629062 (211)\ttotal: 39.1s\tremaining: 58.2s\n",
      "402:\tlearn: 0.3795850\ttest: 0.4636658\tbest: 0.4629062 (211)\ttotal: 39.2s\tremaining: 58.1s\n",
      "403:\tlearn: 0.3793744\ttest: 0.4634960\tbest: 0.4629062 (211)\ttotal: 39.4s\tremaining: 58.1s\n",
      "404:\tlearn: 0.3793729\ttest: 0.4634958\tbest: 0.4629062 (211)\ttotal: 39.4s\tremaining: 57.9s\n",
      "405:\tlearn: 0.3793210\ttest: 0.4634448\tbest: 0.4629062 (211)\ttotal: 39.6s\tremaining: 57.9s\n",
      "406:\tlearn: 0.3793070\ttest: 0.4635152\tbest: 0.4629062 (211)\ttotal: 39.7s\tremaining: 57.8s\n",
      "407:\tlearn: 0.3792723\ttest: 0.4635010\tbest: 0.4629062 (211)\ttotal: 39.9s\tremaining: 57.8s\n",
      "408:\tlearn: 0.3792702\ttest: 0.4635158\tbest: 0.4629062 (211)\ttotal: 39.9s\tremaining: 57.7s\n",
      "409:\tlearn: 0.3792479\ttest: 0.4635394\tbest: 0.4629062 (211)\ttotal: 40s\tremaining: 57.6s\n",
      "410:\tlearn: 0.3792468\ttest: 0.4635393\tbest: 0.4629062 (211)\ttotal: 40.1s\tremaining: 57.5s\n",
      "411:\tlearn: 0.3792312\ttest: 0.4634952\tbest: 0.4629062 (211)\ttotal: 40.3s\tremaining: 57.5s\n",
      "412:\tlearn: 0.3790398\ttest: 0.4634639\tbest: 0.4629062 (211)\ttotal: 40.4s\tremaining: 57.4s\n",
      "413:\tlearn: 0.3789985\ttest: 0.4634605\tbest: 0.4629062 (211)\ttotal: 40.5s\tremaining: 57.3s\n",
      "414:\tlearn: 0.3789679\ttest: 0.4634610\tbest: 0.4629062 (211)\ttotal: 40.6s\tremaining: 57.2s\n",
      "415:\tlearn: 0.3786784\ttest: 0.4634338\tbest: 0.4629062 (211)\ttotal: 40.7s\tremaining: 57.1s\n",
      "416:\tlearn: 0.3786480\ttest: 0.4633285\tbest: 0.4629062 (211)\ttotal: 40.8s\tremaining: 57.1s\n",
      "417:\tlearn: 0.3785959\ttest: 0.4633162\tbest: 0.4629062 (211)\ttotal: 41s\tremaining: 57s\n",
      "418:\tlearn: 0.3784972\ttest: 0.4632975\tbest: 0.4629062 (211)\ttotal: 41.1s\tremaining: 56.9s\n",
      "419:\tlearn: 0.3783881\ttest: 0.4632145\tbest: 0.4629062 (211)\ttotal: 41.1s\tremaining: 56.8s\n",
      "420:\tlearn: 0.3782522\ttest: 0.4632691\tbest: 0.4629062 (211)\ttotal: 41.2s\tremaining: 56.7s\n",
      "421:\tlearn: 0.3781988\ttest: 0.4633066\tbest: 0.4629062 (211)\ttotal: 41.4s\tremaining: 56.7s\n",
      "422:\tlearn: 0.3781835\ttest: 0.4632732\tbest: 0.4629062 (211)\ttotal: 41.5s\tremaining: 56.7s\n",
      "423:\tlearn: 0.3781473\ttest: 0.4632756\tbest: 0.4629062 (211)\ttotal: 41.6s\tremaining: 56.5s\n",
      "424:\tlearn: 0.3779521\ttest: 0.4633553\tbest: 0.4629062 (211)\ttotal: 41.8s\tremaining: 56.5s\n",
      "425:\tlearn: 0.3779484\ttest: 0.4633772\tbest: 0.4629062 (211)\ttotal: 41.9s\tremaining: 56.5s\n",
      "426:\tlearn: 0.3779042\ttest: 0.4633221\tbest: 0.4629062 (211)\ttotal: 42s\tremaining: 56.4s\n",
      "427:\tlearn: 0.3779010\ttest: 0.4633284\tbest: 0.4629062 (211)\ttotal: 42.1s\tremaining: 56.3s\n",
      "428:\tlearn: 0.3777509\ttest: 0.4633864\tbest: 0.4629062 (211)\ttotal: 42.2s\tremaining: 56.2s\n",
      "429:\tlearn: 0.3775774\ttest: 0.4634578\tbest: 0.4629062 (211)\ttotal: 42.3s\tremaining: 56s\n",
      "430:\tlearn: 0.3773057\ttest: 0.4634802\tbest: 0.4629062 (211)\ttotal: 42.4s\tremaining: 55.9s\n",
      "431:\tlearn: 0.3767500\ttest: 0.4637838\tbest: 0.4629062 (211)\ttotal: 42.5s\tremaining: 55.8s\n",
      "432:\tlearn: 0.3767489\ttest: 0.4637937\tbest: 0.4629062 (211)\ttotal: 42.5s\tremaining: 55.7s\n",
      "433:\tlearn: 0.3766590\ttest: 0.4637640\tbest: 0.4629062 (211)\ttotal: 42.6s\tremaining: 55.6s\n",
      "434:\tlearn: 0.3765244\ttest: 0.4639022\tbest: 0.4629062 (211)\ttotal: 42.7s\tremaining: 55.5s\n",
      "435:\tlearn: 0.3764691\ttest: 0.4638949\tbest: 0.4629062 (211)\ttotal: 42.8s\tremaining: 55.4s\n",
      "436:\tlearn: 0.3763690\ttest: 0.4638380\tbest: 0.4629062 (211)\ttotal: 42.9s\tremaining: 55.3s\n",
      "437:\tlearn: 0.3762530\ttest: 0.4639200\tbest: 0.4629062 (211)\ttotal: 43s\tremaining: 55.2s\n",
      "438:\tlearn: 0.3761638\ttest: 0.4638980\tbest: 0.4629062 (211)\ttotal: 43.1s\tremaining: 55.1s\n",
      "439:\tlearn: 0.3760742\ttest: 0.4639622\tbest: 0.4629062 (211)\ttotal: 43.2s\tremaining: 55s\n",
      "440:\tlearn: 0.3760598\ttest: 0.4640282\tbest: 0.4629062 (211)\ttotal: 43.3s\tremaining: 54.9s\n",
      "441:\tlearn: 0.3759014\ttest: 0.4639942\tbest: 0.4629062 (211)\ttotal: 43.5s\tremaining: 54.9s\n",
      "442:\tlearn: 0.3758625\ttest: 0.4639837\tbest: 0.4629062 (211)\ttotal: 43.6s\tremaining: 54.8s\n",
      "443:\tlearn: 0.3757225\ttest: 0.4640446\tbest: 0.4629062 (211)\ttotal: 43.7s\tremaining: 54.7s\n",
      "444:\tlearn: 0.3756242\ttest: 0.4641453\tbest: 0.4629062 (211)\ttotal: 43.8s\tremaining: 54.7s\n",
      "445:\tlearn: 0.3756226\ttest: 0.4641453\tbest: 0.4629062 (211)\ttotal: 43.9s\tremaining: 54.6s\n",
      "446:\tlearn: 0.3756155\ttest: 0.4641463\tbest: 0.4629062 (211)\ttotal: 44.1s\tremaining: 54.5s\n",
      "447:\tlearn: 0.3755277\ttest: 0.4641550\tbest: 0.4629062 (211)\ttotal: 44.2s\tremaining: 54.5s\n",
      "448:\tlearn: 0.3753699\ttest: 0.4642589\tbest: 0.4629062 (211)\ttotal: 44.3s\tremaining: 54.4s\n",
      "449:\tlearn: 0.3753639\ttest: 0.4642627\tbest: 0.4629062 (211)\ttotal: 44.4s\tremaining: 54.3s\n",
      "450:\tlearn: 0.3753528\ttest: 0.4642264\tbest: 0.4629062 (211)\ttotal: 44.6s\tremaining: 54.3s\n",
      "451:\tlearn: 0.3753412\ttest: 0.4642083\tbest: 0.4629062 (211)\ttotal: 44.7s\tremaining: 54.2s\n",
      "452:\tlearn: 0.3752506\ttest: 0.4642583\tbest: 0.4629062 (211)\ttotal: 44.8s\tremaining: 54.2s\n",
      "453:\tlearn: 0.3752073\ttest: 0.4642593\tbest: 0.4629062 (211)\ttotal: 44.9s\tremaining: 54s\n",
      "454:\tlearn: 0.3751838\ttest: 0.4642600\tbest: 0.4629062 (211)\ttotal: 45s\tremaining: 53.9s\n",
      "455:\tlearn: 0.3751128\ttest: 0.4643216\tbest: 0.4629062 (211)\ttotal: 45.1s\tremaining: 53.8s\n",
      "456:\tlearn: 0.3751119\ttest: 0.4643211\tbest: 0.4629062 (211)\ttotal: 45.3s\tremaining: 53.8s\n",
      "457:\tlearn: 0.3750672\ttest: 0.4643289\tbest: 0.4629062 (211)\ttotal: 45.4s\tremaining: 53.7s\n",
      "458:\tlearn: 0.3749973\ttest: 0.4643198\tbest: 0.4629062 (211)\ttotal: 45.5s\tremaining: 53.6s\n",
      "459:\tlearn: 0.3748878\ttest: 0.4642059\tbest: 0.4629062 (211)\ttotal: 45.6s\tremaining: 53.6s\n",
      "460:\tlearn: 0.3747850\ttest: 0.4642296\tbest: 0.4629062 (211)\ttotal: 45.8s\tremaining: 53.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461:\tlearn: 0.3746848\ttest: 0.4641573\tbest: 0.4629062 (211)\ttotal: 45.9s\tremaining: 53.4s\n",
      "462:\tlearn: 0.3746483\ttest: 0.4641228\tbest: 0.4629062 (211)\ttotal: 46s\tremaining: 53.4s\n",
      "463:\tlearn: 0.3746426\ttest: 0.4641281\tbest: 0.4629062 (211)\ttotal: 46.2s\tremaining: 53.4s\n",
      "464:\tlearn: 0.3744694\ttest: 0.4640937\tbest: 0.4629062 (211)\ttotal: 46.3s\tremaining: 53.2s\n",
      "465:\tlearn: 0.3743263\ttest: 0.4640599\tbest: 0.4629062 (211)\ttotal: 46.4s\tremaining: 53.1s\n",
      "466:\tlearn: 0.3742822\ttest: 0.4641796\tbest: 0.4629062 (211)\ttotal: 46.5s\tremaining: 53s\n",
      "467:\tlearn: 0.3742767\ttest: 0.4641710\tbest: 0.4629062 (211)\ttotal: 46.6s\tremaining: 53s\n",
      "468:\tlearn: 0.3742637\ttest: 0.4642071\tbest: 0.4629062 (211)\ttotal: 46.7s\tremaining: 52.9s\n",
      "469:\tlearn: 0.3741993\ttest: 0.4643047\tbest: 0.4629062 (211)\ttotal: 46.8s\tremaining: 52.8s\n",
      "470:\tlearn: 0.3741681\ttest: 0.4643116\tbest: 0.4629062 (211)\ttotal: 47s\tremaining: 52.7s\n",
      "471:\tlearn: 0.3739705\ttest: 0.4644271\tbest: 0.4629062 (211)\ttotal: 47.1s\tremaining: 52.7s\n",
      "472:\tlearn: 0.3736985\ttest: 0.4646395\tbest: 0.4629062 (211)\ttotal: 47.2s\tremaining: 52.6s\n",
      "473:\tlearn: 0.3735885\ttest: 0.4645909\tbest: 0.4629062 (211)\ttotal: 47.3s\tremaining: 52.5s\n",
      "474:\tlearn: 0.3735716\ttest: 0.4645867\tbest: 0.4629062 (211)\ttotal: 47.4s\tremaining: 52.4s\n",
      "475:\tlearn: 0.3735157\ttest: 0.4646432\tbest: 0.4629062 (211)\ttotal: 47.5s\tremaining: 52.3s\n",
      "476:\tlearn: 0.3734203\ttest: 0.4646565\tbest: 0.4629062 (211)\ttotal: 47.6s\tremaining: 52.2s\n",
      "477:\tlearn: 0.3733783\ttest: 0.4646280\tbest: 0.4629062 (211)\ttotal: 47.7s\tremaining: 52.1s\n",
      "478:\tlearn: 0.3731618\ttest: 0.4645623\tbest: 0.4629062 (211)\ttotal: 47.9s\tremaining: 52.1s\n",
      "479:\tlearn: 0.3731391\ttest: 0.4645352\tbest: 0.4629062 (211)\ttotal: 48s\tremaining: 52s\n",
      "480:\tlearn: 0.3731250\ttest: 0.4645125\tbest: 0.4629062 (211)\ttotal: 48.1s\tremaining: 51.9s\n",
      "481:\tlearn: 0.3730396\ttest: 0.4645561\tbest: 0.4629062 (211)\ttotal: 48.2s\tremaining: 51.8s\n",
      "482:\tlearn: 0.3726839\ttest: 0.4646890\tbest: 0.4629062 (211)\ttotal: 48.4s\tremaining: 51.8s\n",
      "483:\tlearn: 0.3726833\ttest: 0.4646833\tbest: 0.4629062 (211)\ttotal: 48.4s\tremaining: 51.6s\n",
      "484:\tlearn: 0.3724549\ttest: 0.4648044\tbest: 0.4629062 (211)\ttotal: 48.5s\tremaining: 51.5s\n",
      "485:\tlearn: 0.3723562\ttest: 0.4648652\tbest: 0.4629062 (211)\ttotal: 48.7s\tremaining: 51.5s\n",
      "486:\tlearn: 0.3723504\ttest: 0.4648730\tbest: 0.4629062 (211)\ttotal: 48.8s\tremaining: 51.4s\n",
      "487:\tlearn: 0.3722600\ttest: 0.4649859\tbest: 0.4629062 (211)\ttotal: 48.9s\tremaining: 51.3s\n",
      "488:\tlearn: 0.3721426\ttest: 0.4649322\tbest: 0.4629062 (211)\ttotal: 49s\tremaining: 51.2s\n",
      "489:\tlearn: 0.3720423\ttest: 0.4648348\tbest: 0.4629062 (211)\ttotal: 49.2s\tremaining: 51.2s\n",
      "490:\tlearn: 0.3720400\ttest: 0.4648362\tbest: 0.4629062 (211)\ttotal: 49.3s\tremaining: 51.1s\n",
      "491:\tlearn: 0.3720387\ttest: 0.4648482\tbest: 0.4629062 (211)\ttotal: 49.4s\tremaining: 51s\n",
      "492:\tlearn: 0.3718749\ttest: 0.4646382\tbest: 0.4629062 (211)\ttotal: 49.4s\tremaining: 50.9s\n",
      "493:\tlearn: 0.3718043\ttest: 0.4645753\tbest: 0.4629062 (211)\ttotal: 49.5s\tremaining: 50.7s\n",
      "494:\tlearn: 0.3716012\ttest: 0.4644535\tbest: 0.4629062 (211)\ttotal: 49.7s\tremaining: 50.7s\n",
      "495:\tlearn: 0.3715997\ttest: 0.4644550\tbest: 0.4629062 (211)\ttotal: 49.8s\tremaining: 50.7s\n",
      "496:\tlearn: 0.3715403\ttest: 0.4644760\tbest: 0.4629062 (211)\ttotal: 49.9s\tremaining: 50.5s\n",
      "497:\tlearn: 0.3712111\ttest: 0.4644982\tbest: 0.4629062 (211)\ttotal: 50.1s\tremaining: 50.5s\n",
      "498:\tlearn: 0.3711760\ttest: 0.4645027\tbest: 0.4629062 (211)\ttotal: 50.3s\tremaining: 50.5s\n",
      "499:\tlearn: 0.3710975\ttest: 0.4644568\tbest: 0.4629062 (211)\ttotal: 50.4s\tremaining: 50.4s\n",
      "500:\tlearn: 0.3709602\ttest: 0.4645096\tbest: 0.4629062 (211)\ttotal: 50.5s\tremaining: 50.3s\n",
      "501:\tlearn: 0.3708172\ttest: 0.4646089\tbest: 0.4629062 (211)\ttotal: 50.7s\tremaining: 50.3s\n",
      "502:\tlearn: 0.3707235\ttest: 0.4646551\tbest: 0.4629062 (211)\ttotal: 50.8s\tremaining: 50.2s\n",
      "503:\tlearn: 0.3706728\ttest: 0.4646321\tbest: 0.4629062 (211)\ttotal: 50.9s\tremaining: 50.1s\n",
      "504:\tlearn: 0.3706724\ttest: 0.4646282\tbest: 0.4629062 (211)\ttotal: 51.1s\tremaining: 50s\n",
      "505:\tlearn: 0.3706660\ttest: 0.4646169\tbest: 0.4629062 (211)\ttotal: 51.2s\tremaining: 50s\n",
      "506:\tlearn: 0.3705866\ttest: 0.4646746\tbest: 0.4629062 (211)\ttotal: 51.3s\tremaining: 49.8s\n",
      "507:\tlearn: 0.3702509\ttest: 0.4646649\tbest: 0.4629062 (211)\ttotal: 51.4s\tremaining: 49.8s\n",
      "508:\tlearn: 0.3701823\ttest: 0.4647977\tbest: 0.4629062 (211)\ttotal: 51.6s\tremaining: 49.7s\n",
      "509:\tlearn: 0.3700004\ttest: 0.4647371\tbest: 0.4629062 (211)\ttotal: 51.7s\tremaining: 49.7s\n",
      "510:\tlearn: 0.3698597\ttest: 0.4646804\tbest: 0.4629062 (211)\ttotal: 51.8s\tremaining: 49.6s\n",
      "511:\tlearn: 0.3698489\ttest: 0.4646940\tbest: 0.4629062 (211)\ttotal: 51.9s\tremaining: 49.4s\n",
      "512:\tlearn: 0.3696867\ttest: 0.4645866\tbest: 0.4629062 (211)\ttotal: 52s\tremaining: 49.4s\n",
      "513:\tlearn: 0.3696488\ttest: 0.4645961\tbest: 0.4629062 (211)\ttotal: 52.1s\tremaining: 49.2s\n",
      "514:\tlearn: 0.3696314\ttest: 0.4646065\tbest: 0.4629062 (211)\ttotal: 52.2s\tremaining: 49.2s\n",
      "515:\tlearn: 0.3694711\ttest: 0.4645525\tbest: 0.4629062 (211)\ttotal: 52.4s\tremaining: 49.1s\n",
      "516:\tlearn: 0.3693202\ttest: 0.4645641\tbest: 0.4629062 (211)\ttotal: 52.5s\tremaining: 49s\n",
      "517:\tlearn: 0.3693117\ttest: 0.4645632\tbest: 0.4629062 (211)\ttotal: 52.5s\tremaining: 48.9s\n",
      "518:\tlearn: 0.3690866\ttest: 0.4645244\tbest: 0.4629062 (211)\ttotal: 52.6s\tremaining: 48.8s\n",
      "519:\tlearn: 0.3690660\ttest: 0.4645193\tbest: 0.4629062 (211)\ttotal: 52.8s\tremaining: 48.7s\n",
      "520:\tlearn: 0.3689481\ttest: 0.4646046\tbest: 0.4629062 (211)\ttotal: 52.9s\tremaining: 48.6s\n",
      "521:\tlearn: 0.3689407\ttest: 0.4646237\tbest: 0.4629062 (211)\ttotal: 53s\tremaining: 48.5s\n",
      "522:\tlearn: 0.3689356\ttest: 0.4646186\tbest: 0.4629062 (211)\ttotal: 53.1s\tremaining: 48.5s\n",
      "523:\tlearn: 0.3689355\ttest: 0.4646193\tbest: 0.4629062 (211)\ttotal: 53.2s\tremaining: 48.3s\n",
      "524:\tlearn: 0.3687897\ttest: 0.4645038\tbest: 0.4629062 (211)\ttotal: 53.3s\tremaining: 48.3s\n",
      "525:\tlearn: 0.3687297\ttest: 0.4645238\tbest: 0.4629062 (211)\ttotal: 53.4s\tremaining: 48.1s\n",
      "526:\tlearn: 0.3685462\ttest: 0.4645391\tbest: 0.4629062 (211)\ttotal: 53.6s\tremaining: 48.1s\n",
      "527:\tlearn: 0.3685312\ttest: 0.4645450\tbest: 0.4629062 (211)\ttotal: 53.7s\tremaining: 48s\n",
      "528:\tlearn: 0.3684031\ttest: 0.4645935\tbest: 0.4629062 (211)\ttotal: 53.9s\tremaining: 48s\n",
      "529:\tlearn: 0.3683684\ttest: 0.4645702\tbest: 0.4629062 (211)\ttotal: 54s\tremaining: 47.9s\n",
      "530:\tlearn: 0.3682826\ttest: 0.4644727\tbest: 0.4629062 (211)\ttotal: 54.2s\tremaining: 47.9s\n",
      "531:\tlearn: 0.3682803\ttest: 0.4644732\tbest: 0.4629062 (211)\ttotal: 54.3s\tremaining: 47.8s\n",
      "532:\tlearn: 0.3681915\ttest: 0.4645147\tbest: 0.4629062 (211)\ttotal: 54.4s\tremaining: 47.7s\n",
      "533:\tlearn: 0.3680950\ttest: 0.4646043\tbest: 0.4629062 (211)\ttotal: 54.5s\tremaining: 47.6s\n",
      "534:\tlearn: 0.3680950\ttest: 0.4646044\tbest: 0.4629062 (211)\ttotal: 54.6s\tremaining: 47.4s\n",
      "535:\tlearn: 0.3680825\ttest: 0.4646082\tbest: 0.4629062 (211)\ttotal: 54.7s\tremaining: 47.4s\n",
      "536:\tlearn: 0.3678580\ttest: 0.4646995\tbest: 0.4629062 (211)\ttotal: 54.9s\tremaining: 47.3s\n",
      "537:\tlearn: 0.3678345\ttest: 0.4646993\tbest: 0.4629062 (211)\ttotal: 55s\tremaining: 47.3s\n",
      "538:\tlearn: 0.3678128\ttest: 0.4646666\tbest: 0.4629062 (211)\ttotal: 55.2s\tremaining: 47.2s\n",
      "539:\tlearn: 0.3677428\ttest: 0.4647374\tbest: 0.4629062 (211)\ttotal: 55.2s\tremaining: 47.1s\n",
      "540:\tlearn: 0.3675795\ttest: 0.4646874\tbest: 0.4629062 (211)\ttotal: 55.4s\tremaining: 47s\n",
      "541:\tlearn: 0.3674663\ttest: 0.4647447\tbest: 0.4629062 (211)\ttotal: 55.5s\tremaining: 46.9s\n",
      "542:\tlearn: 0.3674569\ttest: 0.4647462\tbest: 0.4629062 (211)\ttotal: 55.6s\tremaining: 46.8s\n",
      "543:\tlearn: 0.3674091\ttest: 0.4647243\tbest: 0.4629062 (211)\ttotal: 55.7s\tremaining: 46.7s\n",
      "544:\tlearn: 0.3673632\ttest: 0.4646577\tbest: 0.4629062 (211)\ttotal: 55.8s\tremaining: 46.6s\n",
      "545:\tlearn: 0.3673333\ttest: 0.4646647\tbest: 0.4629062 (211)\ttotal: 56s\tremaining: 46.5s\n",
      "546:\tlearn: 0.3671895\ttest: 0.4647018\tbest: 0.4629062 (211)\ttotal: 56.1s\tremaining: 46.4s\n",
      "547:\tlearn: 0.3670122\ttest: 0.4647813\tbest: 0.4629062 (211)\ttotal: 56.1s\tremaining: 46.3s\n",
      "548:\tlearn: 0.3669590\ttest: 0.4648490\tbest: 0.4629062 (211)\ttotal: 56.3s\tremaining: 46.2s\n",
      "549:\tlearn: 0.3669384\ttest: 0.4648735\tbest: 0.4629062 (211)\ttotal: 56.3s\tremaining: 46.1s\n",
      "550:\tlearn: 0.3668275\ttest: 0.4649276\tbest: 0.4629062 (211)\ttotal: 56.4s\tremaining: 46s\n",
      "551:\tlearn: 0.3667732\ttest: 0.4649342\tbest: 0.4629062 (211)\ttotal: 56.5s\tremaining: 45.9s\n",
      "552:\tlearn: 0.3667168\ttest: 0.4648836\tbest: 0.4629062 (211)\ttotal: 56.6s\tremaining: 45.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553:\tlearn: 0.3666140\ttest: 0.4647916\tbest: 0.4629062 (211)\ttotal: 56.8s\tremaining: 45.7s\n",
      "554:\tlearn: 0.3665776\ttest: 0.4648119\tbest: 0.4629062 (211)\ttotal: 56.8s\tremaining: 45.6s\n",
      "555:\tlearn: 0.3663540\ttest: 0.4648478\tbest: 0.4629062 (211)\ttotal: 57s\tremaining: 45.5s\n",
      "556:\tlearn: 0.3661270\ttest: 0.4647205\tbest: 0.4629062 (211)\ttotal: 57.1s\tremaining: 45.4s\n",
      "557:\tlearn: 0.3661136\ttest: 0.4646952\tbest: 0.4629062 (211)\ttotal: 57.2s\tremaining: 45.3s\n",
      "558:\tlearn: 0.3658917\ttest: 0.4647286\tbest: 0.4629062 (211)\ttotal: 57.3s\tremaining: 45.2s\n",
      "559:\tlearn: 0.3657580\ttest: 0.4647818\tbest: 0.4629062 (211)\ttotal: 57.4s\tremaining: 45.1s\n",
      "560:\tlearn: 0.3655920\ttest: 0.4647233\tbest: 0.4629062 (211)\ttotal: 57.5s\tremaining: 45s\n",
      "561:\tlearn: 0.3655072\ttest: 0.4647366\tbest: 0.4629062 (211)\ttotal: 57.6s\tremaining: 44.9s\n",
      "562:\tlearn: 0.3654753\ttest: 0.4647327\tbest: 0.4629062 (211)\ttotal: 57.7s\tremaining: 44.8s\n",
      "563:\tlearn: 0.3652902\ttest: 0.4648053\tbest: 0.4629062 (211)\ttotal: 57.8s\tremaining: 44.7s\n",
      "564:\tlearn: 0.3652079\ttest: 0.4648472\tbest: 0.4629062 (211)\ttotal: 57.9s\tremaining: 44.6s\n",
      "565:\tlearn: 0.3650765\ttest: 0.4648480\tbest: 0.4629062 (211)\ttotal: 58s\tremaining: 44.4s\n",
      "566:\tlearn: 0.3650488\ttest: 0.4648342\tbest: 0.4629062 (211)\ttotal: 58.1s\tremaining: 44.3s\n",
      "567:\tlearn: 0.3650325\ttest: 0.4648970\tbest: 0.4629062 (211)\ttotal: 58.1s\tremaining: 44.2s\n",
      "568:\tlearn: 0.3650234\ttest: 0.4648950\tbest: 0.4629062 (211)\ttotal: 58.3s\tremaining: 44.1s\n",
      "569:\tlearn: 0.3650013\ttest: 0.4649097\tbest: 0.4629062 (211)\ttotal: 58.4s\tremaining: 44s\n",
      "570:\tlearn: 0.3649839\ttest: 0.4649172\tbest: 0.4629062 (211)\ttotal: 58.4s\tremaining: 43.9s\n",
      "571:\tlearn: 0.3648323\ttest: 0.4647081\tbest: 0.4629062 (211)\ttotal: 58.6s\tremaining: 43.8s\n",
      "572:\tlearn: 0.3647166\ttest: 0.4646926\tbest: 0.4629062 (211)\ttotal: 58.6s\tremaining: 43.7s\n",
      "573:\tlearn: 0.3647159\ttest: 0.4646797\tbest: 0.4629062 (211)\ttotal: 58.7s\tremaining: 43.6s\n",
      "574:\tlearn: 0.3646443\ttest: 0.4647135\tbest: 0.4629062 (211)\ttotal: 58.8s\tremaining: 43.5s\n",
      "575:\tlearn: 0.3646203\ttest: 0.4646823\tbest: 0.4629062 (211)\ttotal: 58.9s\tremaining: 43.4s\n",
      "576:\tlearn: 0.3643445\ttest: 0.4646415\tbest: 0.4629062 (211)\ttotal: 59s\tremaining: 43.3s\n",
      "577:\tlearn: 0.3643416\ttest: 0.4646491\tbest: 0.4629062 (211)\ttotal: 59.1s\tremaining: 43.2s\n",
      "578:\tlearn: 0.3641842\ttest: 0.4646940\tbest: 0.4629062 (211)\ttotal: 59.2s\tremaining: 43.1s\n",
      "579:\tlearn: 0.3640881\ttest: 0.4647049\tbest: 0.4629062 (211)\ttotal: 59.3s\tremaining: 43s\n",
      "580:\tlearn: 0.3640571\ttest: 0.4646926\tbest: 0.4629062 (211)\ttotal: 59.4s\tremaining: 42.8s\n",
      "581:\tlearn: 0.3639703\ttest: 0.4648054\tbest: 0.4629062 (211)\ttotal: 59.5s\tremaining: 42.7s\n",
      "582:\tlearn: 0.3639674\ttest: 0.4648099\tbest: 0.4629062 (211)\ttotal: 59.6s\tremaining: 42.6s\n",
      "583:\tlearn: 0.3638425\ttest: 0.4647560\tbest: 0.4629062 (211)\ttotal: 59.7s\tremaining: 42.5s\n",
      "584:\tlearn: 0.3637882\ttest: 0.4647033\tbest: 0.4629062 (211)\ttotal: 59.8s\tremaining: 42.4s\n",
      "585:\tlearn: 0.3637455\ttest: 0.4647284\tbest: 0.4629062 (211)\ttotal: 59.9s\tremaining: 42.3s\n",
      "586:\tlearn: 0.3637248\ttest: 0.4647506\tbest: 0.4629062 (211)\ttotal: 59.9s\tremaining: 42.2s\n",
      "587:\tlearn: 0.3636880\ttest: 0.4648454\tbest: 0.4629062 (211)\ttotal: 1m\tremaining: 42.1s\n",
      "588:\tlearn: 0.3636160\ttest: 0.4648723\tbest: 0.4629062 (211)\ttotal: 1m\tremaining: 42s\n",
      "589:\tlearn: 0.3634837\ttest: 0.4648180\tbest: 0.4629062 (211)\ttotal: 1m\tremaining: 41.8s\n",
      "590:\tlearn: 0.3633822\ttest: 0.4648501\tbest: 0.4629062 (211)\ttotal: 1m\tremaining: 41.7s\n",
      "591:\tlearn: 0.3633764\ttest: 0.4648519\tbest: 0.4629062 (211)\ttotal: 1m\tremaining: 41.6s\n",
      "592:\tlearn: 0.3633348\ttest: 0.4648711\tbest: 0.4629062 (211)\ttotal: 1m\tremaining: 41.5s\n",
      "593:\tlearn: 0.3633155\ttest: 0.4649454\tbest: 0.4629062 (211)\ttotal: 1m\tremaining: 41.4s\n",
      "594:\tlearn: 0.3632806\ttest: 0.4649345\tbest: 0.4629062 (211)\ttotal: 1m\tremaining: 41.3s\n",
      "595:\tlearn: 0.3629486\ttest: 0.4649766\tbest: 0.4629062 (211)\ttotal: 1m\tremaining: 41.2s\n",
      "596:\tlearn: 0.3628517\ttest: 0.4649527\tbest: 0.4629062 (211)\ttotal: 1m\tremaining: 41.1s\n",
      "597:\tlearn: 0.3628195\ttest: 0.4649623\tbest: 0.4629062 (211)\ttotal: 1m\tremaining: 41s\n",
      "598:\tlearn: 0.3627504\ttest: 0.4649678\tbest: 0.4629062 (211)\ttotal: 1m 1s\tremaining: 40.8s\n",
      "599:\tlearn: 0.3627479\ttest: 0.4649727\tbest: 0.4629062 (211)\ttotal: 1m 1s\tremaining: 40.8s\n",
      "600:\tlearn: 0.3626199\ttest: 0.4649856\tbest: 0.4629062 (211)\ttotal: 1m 1s\tremaining: 40.6s\n",
      "601:\tlearn: 0.3624845\ttest: 0.4648765\tbest: 0.4629062 (211)\ttotal: 1m 1s\tremaining: 40.6s\n",
      "602:\tlearn: 0.3623976\ttest: 0.4648202\tbest: 0.4629062 (211)\ttotal: 1m 1s\tremaining: 40.5s\n",
      "603:\tlearn: 0.3623926\ttest: 0.4648170\tbest: 0.4629062 (211)\ttotal: 1m 1s\tremaining: 40.4s\n",
      "604:\tlearn: 0.3623638\ttest: 0.4648351\tbest: 0.4629062 (211)\ttotal: 1m 1s\tremaining: 40.3s\n",
      "605:\tlearn: 0.3623535\ttest: 0.4648361\tbest: 0.4629062 (211)\ttotal: 1m 1s\tremaining: 40.2s\n",
      "606:\tlearn: 0.3623402\ttest: 0.4648148\tbest: 0.4629062 (211)\ttotal: 1m 1s\tremaining: 40s\n",
      "607:\tlearn: 0.3622537\ttest: 0.4648156\tbest: 0.4629062 (211)\ttotal: 1m 1s\tremaining: 39.9s\n",
      "608:\tlearn: 0.3621336\ttest: 0.4649005\tbest: 0.4629062 (211)\ttotal: 1m 2s\tremaining: 39.9s\n",
      "609:\tlearn: 0.3621244\ttest: 0.4648911\tbest: 0.4629062 (211)\ttotal: 1m 2s\tremaining: 39.8s\n",
      "610:\tlearn: 0.3620889\ttest: 0.4649070\tbest: 0.4629062 (211)\ttotal: 1m 2s\tremaining: 39.7s\n",
      "611:\tlearn: 0.3620756\ttest: 0.4649087\tbest: 0.4629062 (211)\ttotal: 1m 2s\tremaining: 39.6s\n",
      "612:\tlearn: 0.3619914\ttest: 0.4649684\tbest: 0.4629062 (211)\ttotal: 1m 2s\tremaining: 39.4s\n",
      "613:\tlearn: 0.3619905\ttest: 0.4649651\tbest: 0.4629062 (211)\ttotal: 1m 2s\tremaining: 39.3s\n",
      "614:\tlearn: 0.3616503\ttest: 0.4648567\tbest: 0.4629062 (211)\ttotal: 1m 2s\tremaining: 39.2s\n",
      "615:\tlearn: 0.3616114\ttest: 0.4647903\tbest: 0.4629062 (211)\ttotal: 1m 2s\tremaining: 39.2s\n",
      "616:\tlearn: 0.3616094\ttest: 0.4647947\tbest: 0.4629062 (211)\ttotal: 1m 2s\tremaining: 39.1s\n",
      "617:\tlearn: 0.3615178\ttest: 0.4648605\tbest: 0.4629062 (211)\ttotal: 1m 2s\tremaining: 38.9s\n",
      "618:\tlearn: 0.3614536\ttest: 0.4649774\tbest: 0.4629062 (211)\ttotal: 1m 3s\tremaining: 38.8s\n",
      "619:\tlearn: 0.3613925\ttest: 0.4650039\tbest: 0.4629062 (211)\ttotal: 1m 3s\tremaining: 38.7s\n",
      "620:\tlearn: 0.3613248\ttest: 0.4650358\tbest: 0.4629062 (211)\ttotal: 1m 3s\tremaining: 38.7s\n",
      "621:\tlearn: 0.3612262\ttest: 0.4650532\tbest: 0.4629062 (211)\ttotal: 1m 3s\tremaining: 38.6s\n",
      "622:\tlearn: 0.3612222\ttest: 0.4650548\tbest: 0.4629062 (211)\ttotal: 1m 3s\tremaining: 38.5s\n",
      "623:\tlearn: 0.3611381\ttest: 0.4650675\tbest: 0.4629062 (211)\ttotal: 1m 3s\tremaining: 38.4s\n",
      "624:\tlearn: 0.3610290\ttest: 0.4649708\tbest: 0.4629062 (211)\ttotal: 1m 3s\tremaining: 38.3s\n",
      "625:\tlearn: 0.3610046\ttest: 0.4650227\tbest: 0.4629062 (211)\ttotal: 1m 3s\tremaining: 38.2s\n",
      "626:\tlearn: 0.3609730\ttest: 0.4650113\tbest: 0.4629062 (211)\ttotal: 1m 4s\tremaining: 38.1s\n",
      "627:\tlearn: 0.3609417\ttest: 0.4650722\tbest: 0.4629062 (211)\ttotal: 1m 4s\tremaining: 38s\n",
      "628:\tlearn: 0.3609164\ttest: 0.4650673\tbest: 0.4629062 (211)\ttotal: 1m 4s\tremaining: 37.9s\n",
      "629:\tlearn: 0.3608103\ttest: 0.4651124\tbest: 0.4629062 (211)\ttotal: 1m 4s\tremaining: 37.7s\n",
      "630:\tlearn: 0.3606604\ttest: 0.4651617\tbest: 0.4629062 (211)\ttotal: 1m 4s\tremaining: 37.6s\n",
      "631:\tlearn: 0.3604231\ttest: 0.4652231\tbest: 0.4629062 (211)\ttotal: 1m 4s\tremaining: 37.6s\n",
      "632:\tlearn: 0.3604216\ttest: 0.4652265\tbest: 0.4629062 (211)\ttotal: 1m 4s\tremaining: 37.5s\n",
      "633:\tlearn: 0.3603655\ttest: 0.4651700\tbest: 0.4629062 (211)\ttotal: 1m 4s\tremaining: 37.4s\n",
      "634:\tlearn: 0.3603633\ttest: 0.4651688\tbest: 0.4629062 (211)\ttotal: 1m 4s\tremaining: 37.2s\n",
      "635:\tlearn: 0.3603408\ttest: 0.4651696\tbest: 0.4629062 (211)\ttotal: 1m 4s\tremaining: 37.1s\n",
      "636:\tlearn: 0.3603408\ttest: 0.4651696\tbest: 0.4629062 (211)\ttotal: 1m 4s\tremaining: 37s\n",
      "637:\tlearn: 0.3602371\ttest: 0.4651594\tbest: 0.4629062 (211)\ttotal: 1m 4s\tremaining: 36.9s\n",
      "638:\tlearn: 0.3602371\ttest: 0.4651596\tbest: 0.4629062 (211)\ttotal: 1m 5s\tremaining: 36.7s\n",
      "639:\tlearn: 0.3602327\ttest: 0.4651787\tbest: 0.4629062 (211)\ttotal: 1m 5s\tremaining: 36.6s\n",
      "640:\tlearn: 0.3601653\ttest: 0.4651727\tbest: 0.4629062 (211)\ttotal: 1m 5s\tremaining: 36.5s\n",
      "641:\tlearn: 0.3601032\ttest: 0.4651845\tbest: 0.4629062 (211)\ttotal: 1m 5s\tremaining: 36.5s\n",
      "642:\tlearn: 0.3601020\ttest: 0.4651877\tbest: 0.4629062 (211)\ttotal: 1m 5s\tremaining: 36.3s\n",
      "643:\tlearn: 0.3601009\ttest: 0.4651911\tbest: 0.4629062 (211)\ttotal: 1m 5s\tremaining: 36.2s\n",
      "644:\tlearn: 0.3600976\ttest: 0.4652083\tbest: 0.4629062 (211)\ttotal: 1m 5s\tremaining: 36.1s\n",
      "645:\tlearn: 0.3599642\ttest: 0.4651143\tbest: 0.4629062 (211)\ttotal: 1m 5s\tremaining: 36s\n",
      "646:\tlearn: 0.3599633\ttest: 0.4651179\tbest: 0.4629062 (211)\ttotal: 1m 5s\tremaining: 35.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647:\tlearn: 0.3599625\ttest: 0.4651218\tbest: 0.4629062 (211)\ttotal: 1m 5s\tremaining: 35.8s\n",
      "648:\tlearn: 0.3598757\ttest: 0.4651610\tbest: 0.4629062 (211)\ttotal: 1m 5s\tremaining: 35.7s\n",
      "649:\tlearn: 0.3598562\ttest: 0.4651564\tbest: 0.4629062 (211)\ttotal: 1m 6s\tremaining: 35.6s\n",
      "650:\tlearn: 0.3597644\ttest: 0.4651378\tbest: 0.4629062 (211)\ttotal: 1m 6s\tremaining: 35.5s\n",
      "651:\tlearn: 0.3597394\ttest: 0.4651414\tbest: 0.4629062 (211)\ttotal: 1m 6s\tremaining: 35.4s\n",
      "652:\tlearn: 0.3596767\ttest: 0.4652258\tbest: 0.4629062 (211)\ttotal: 1m 6s\tremaining: 35.3s\n",
      "653:\tlearn: 0.3596757\ttest: 0.4652257\tbest: 0.4629062 (211)\ttotal: 1m 6s\tremaining: 35.2s\n",
      "654:\tlearn: 0.3593514\ttest: 0.4654881\tbest: 0.4629062 (211)\ttotal: 1m 6s\tremaining: 35.1s\n",
      "655:\tlearn: 0.3593107\ttest: 0.4655487\tbest: 0.4629062 (211)\ttotal: 1m 6s\tremaining: 35s\n",
      "656:\tlearn: 0.3592677\ttest: 0.4654911\tbest: 0.4629062 (211)\ttotal: 1m 6s\tremaining: 34.9s\n",
      "657:\tlearn: 0.3592267\ttest: 0.4654967\tbest: 0.4629062 (211)\ttotal: 1m 6s\tremaining: 34.8s\n",
      "658:\tlearn: 0.3592104\ttest: 0.4655040\tbest: 0.4629062 (211)\ttotal: 1m 7s\tremaining: 34.7s\n",
      "659:\tlearn: 0.3591572\ttest: 0.4655459\tbest: 0.4629062 (211)\ttotal: 1m 7s\tremaining: 34.6s\n",
      "660:\tlearn: 0.3589406\ttest: 0.4656095\tbest: 0.4629062 (211)\ttotal: 1m 7s\tremaining: 34.5s\n",
      "661:\tlearn: 0.3589291\ttest: 0.4655956\tbest: 0.4629062 (211)\ttotal: 1m 7s\tremaining: 34.4s\n",
      "662:\tlearn: 0.3589266\ttest: 0.4656023\tbest: 0.4629062 (211)\ttotal: 1m 7s\tremaining: 34.3s\n",
      "663:\tlearn: 0.3586935\ttest: 0.4655648\tbest: 0.4629062 (211)\ttotal: 1m 7s\tremaining: 34.2s\n",
      "664:\tlearn: 0.3586875\ttest: 0.4655616\tbest: 0.4629062 (211)\ttotal: 1m 7s\tremaining: 34.1s\n",
      "665:\tlearn: 0.3586118\ttest: 0.4655745\tbest: 0.4629062 (211)\ttotal: 1m 7s\tremaining: 34s\n",
      "666:\tlearn: 0.3585807\ttest: 0.4656058\tbest: 0.4629062 (211)\ttotal: 1m 7s\tremaining: 33.9s\n",
      "667:\tlearn: 0.3585538\ttest: 0.4656490\tbest: 0.4629062 (211)\ttotal: 1m 8s\tremaining: 33.8s\n",
      "668:\tlearn: 0.3584060\ttest: 0.4657108\tbest: 0.4629062 (211)\ttotal: 1m 8s\tremaining: 33.8s\n",
      "669:\tlearn: 0.3583803\ttest: 0.4656978\tbest: 0.4629062 (211)\ttotal: 1m 8s\tremaining: 33.6s\n",
      "670:\tlearn: 0.3583338\ttest: 0.4656699\tbest: 0.4629062 (211)\ttotal: 1m 8s\tremaining: 33.5s\n",
      "671:\tlearn: 0.3583305\ttest: 0.4656809\tbest: 0.4629062 (211)\ttotal: 1m 8s\tremaining: 33.4s\n",
      "672:\tlearn: 0.3581461\ttest: 0.4655551\tbest: 0.4629062 (211)\ttotal: 1m 8s\tremaining: 33.4s\n",
      "673:\tlearn: 0.3581432\ttest: 0.4655452\tbest: 0.4629062 (211)\ttotal: 1m 8s\tremaining: 33.3s\n",
      "674:\tlearn: 0.3578923\ttest: 0.4655617\tbest: 0.4629062 (211)\ttotal: 1m 8s\tremaining: 33.1s\n",
      "675:\tlearn: 0.3578019\ttest: 0.4655203\tbest: 0.4629062 (211)\ttotal: 1m 8s\tremaining: 33s\n",
      "676:\tlearn: 0.3577686\ttest: 0.4655143\tbest: 0.4629062 (211)\ttotal: 1m 9s\tremaining: 32.9s\n",
      "677:\tlearn: 0.3577248\ttest: 0.4655699\tbest: 0.4629062 (211)\ttotal: 1m 9s\tremaining: 32.8s\n",
      "678:\tlearn: 0.3577117\ttest: 0.4655564\tbest: 0.4629062 (211)\ttotal: 1m 9s\tremaining: 32.7s\n",
      "679:\tlearn: 0.3575890\ttest: 0.4655706\tbest: 0.4629062 (211)\ttotal: 1m 9s\tremaining: 32.7s\n",
      "680:\tlearn: 0.3574618\ttest: 0.4655194\tbest: 0.4629062 (211)\ttotal: 1m 9s\tremaining: 32.6s\n",
      "681:\tlearn: 0.3573804\ttest: 0.4655779\tbest: 0.4629062 (211)\ttotal: 1m 9s\tremaining: 32.5s\n",
      "682:\tlearn: 0.3573331\ttest: 0.4657504\tbest: 0.4629062 (211)\ttotal: 1m 9s\tremaining: 32.4s\n",
      "683:\tlearn: 0.3573228\ttest: 0.4657258\tbest: 0.4629062 (211)\ttotal: 1m 9s\tremaining: 32.3s\n",
      "684:\tlearn: 0.3572968\ttest: 0.4656996\tbest: 0.4629062 (211)\ttotal: 1m 10s\tremaining: 32.2s\n",
      "685:\tlearn: 0.3572859\ttest: 0.4657004\tbest: 0.4629062 (211)\ttotal: 1m 10s\tremaining: 32.1s\n",
      "686:\tlearn: 0.3572810\ttest: 0.4657078\tbest: 0.4629062 (211)\ttotal: 1m 10s\tremaining: 32s\n",
      "687:\tlearn: 0.3571972\ttest: 0.4658540\tbest: 0.4629062 (211)\ttotal: 1m 10s\tremaining: 31.9s\n",
      "688:\tlearn: 0.3571480\ttest: 0.4658568\tbest: 0.4629062 (211)\ttotal: 1m 10s\tremaining: 31.8s\n",
      "689:\tlearn: 0.3571318\ttest: 0.4658274\tbest: 0.4629062 (211)\ttotal: 1m 10s\tremaining: 31.7s\n",
      "690:\tlearn: 0.3571227\ttest: 0.4658257\tbest: 0.4629062 (211)\ttotal: 1m 10s\tremaining: 31.5s\n",
      "691:\tlearn: 0.3571208\ttest: 0.4658348\tbest: 0.4629062 (211)\ttotal: 1m 10s\tremaining: 31.4s\n",
      "692:\tlearn: 0.3571148\ttest: 0.4658296\tbest: 0.4629062 (211)\ttotal: 1m 10s\tremaining: 31.3s\n",
      "693:\tlearn: 0.3570898\ttest: 0.4658305\tbest: 0.4629062 (211)\ttotal: 1m 10s\tremaining: 31.2s\n",
      "694:\tlearn: 0.3570580\ttest: 0.4658303\tbest: 0.4629062 (211)\ttotal: 1m 10s\tremaining: 31.1s\n",
      "695:\tlearn: 0.3569239\ttest: 0.4658491\tbest: 0.4629062 (211)\ttotal: 1m 11s\tremaining: 31s\n",
      "696:\tlearn: 0.3569212\ttest: 0.4658465\tbest: 0.4629062 (211)\ttotal: 1m 11s\tremaining: 30.9s\n",
      "697:\tlearn: 0.3569085\ttest: 0.4658648\tbest: 0.4629062 (211)\ttotal: 1m 11s\tremaining: 30.8s\n",
      "698:\tlearn: 0.3568437\ttest: 0.4659492\tbest: 0.4629062 (211)\ttotal: 1m 11s\tremaining: 30.7s\n",
      "699:\tlearn: 0.3568437\ttest: 0.4659493\tbest: 0.4629062 (211)\ttotal: 1m 11s\tremaining: 30.6s\n",
      "700:\tlearn: 0.3567756\ttest: 0.4659545\tbest: 0.4629062 (211)\ttotal: 1m 11s\tremaining: 30.5s\n",
      "701:\tlearn: 0.3567205\ttest: 0.4659756\tbest: 0.4629062 (211)\ttotal: 1m 11s\tremaining: 30.4s\n",
      "702:\tlearn: 0.3564549\ttest: 0.4660034\tbest: 0.4629062 (211)\ttotal: 1m 11s\tremaining: 30.3s\n",
      "703:\tlearn: 0.3564516\ttest: 0.4660038\tbest: 0.4629062 (211)\ttotal: 1m 11s\tremaining: 30.1s\n",
      "704:\tlearn: 0.3563927\ttest: 0.4659716\tbest: 0.4629062 (211)\ttotal: 1m 11s\tremaining: 30s\n",
      "705:\tlearn: 0.3563563\ttest: 0.4660030\tbest: 0.4629062 (211)\ttotal: 1m 11s\tremaining: 29.9s\n",
      "706:\tlearn: 0.3563505\ttest: 0.4660012\tbest: 0.4629062 (211)\ttotal: 1m 11s\tremaining: 29.8s\n",
      "707:\tlearn: 0.3563492\ttest: 0.4660004\tbest: 0.4629062 (211)\ttotal: 1m 12s\tremaining: 29.7s\n",
      "708:\tlearn: 0.3563474\ttest: 0.4660009\tbest: 0.4629062 (211)\ttotal: 1m 12s\tremaining: 29.6s\n",
      "709:\tlearn: 0.3563159\ttest: 0.4659905\tbest: 0.4629062 (211)\ttotal: 1m 12s\tremaining: 29.5s\n",
      "710:\tlearn: 0.3563150\ttest: 0.4659938\tbest: 0.4629062 (211)\ttotal: 1m 12s\tremaining: 29.4s\n",
      "711:\tlearn: 0.3562144\ttest: 0.4659885\tbest: 0.4629062 (211)\ttotal: 1m 12s\tremaining: 29.3s\n",
      "712:\tlearn: 0.3562138\ttest: 0.4659902\tbest: 0.4629062 (211)\ttotal: 1m 12s\tremaining: 29.2s\n",
      "713:\tlearn: 0.3561612\ttest: 0.4660049\tbest: 0.4629062 (211)\ttotal: 1m 12s\tremaining: 29.1s\n",
      "714:\tlearn: 0.3561042\ttest: 0.4660445\tbest: 0.4629062 (211)\ttotal: 1m 12s\tremaining: 28.9s\n",
      "715:\tlearn: 0.3560580\ttest: 0.4661450\tbest: 0.4629062 (211)\ttotal: 1m 12s\tremaining: 28.8s\n",
      "716:\tlearn: 0.3559629\ttest: 0.4662672\tbest: 0.4629062 (211)\ttotal: 1m 12s\tremaining: 28.7s\n",
      "717:\tlearn: 0.3559544\ttest: 0.4662898\tbest: 0.4629062 (211)\ttotal: 1m 12s\tremaining: 28.6s\n",
      "718:\tlearn: 0.3558258\ttest: 0.4663404\tbest: 0.4629062 (211)\ttotal: 1m 13s\tremaining: 28.5s\n",
      "719:\tlearn: 0.3558028\ttest: 0.4663417\tbest: 0.4629062 (211)\ttotal: 1m 13s\tremaining: 28.5s\n",
      "720:\tlearn: 0.3557941\ttest: 0.4663504\tbest: 0.4629062 (211)\ttotal: 1m 13s\tremaining: 28.4s\n",
      "721:\tlearn: 0.3557900\ttest: 0.4663503\tbest: 0.4629062 (211)\ttotal: 1m 13s\tremaining: 28.3s\n",
      "722:\tlearn: 0.3556933\ttest: 0.4664320\tbest: 0.4629062 (211)\ttotal: 1m 13s\tremaining: 28.2s\n",
      "723:\tlearn: 0.3556876\ttest: 0.4664364\tbest: 0.4629062 (211)\ttotal: 1m 13s\tremaining: 28.1s\n",
      "724:\tlearn: 0.3556223\ttest: 0.4664354\tbest: 0.4629062 (211)\ttotal: 1m 13s\tremaining: 28s\n",
      "725:\tlearn: 0.3554619\ttest: 0.4665587\tbest: 0.4629062 (211)\ttotal: 1m 13s\tremaining: 27.9s\n",
      "726:\tlearn: 0.3554589\ttest: 0.4665613\tbest: 0.4629062 (211)\ttotal: 1m 14s\tremaining: 27.8s\n",
      "727:\tlearn: 0.3554287\ttest: 0.4665975\tbest: 0.4629062 (211)\ttotal: 1m 14s\tremaining: 27.7s\n",
      "728:\tlearn: 0.3551818\ttest: 0.4668256\tbest: 0.4629062 (211)\ttotal: 1m 14s\tremaining: 27.6s\n",
      "729:\tlearn: 0.3551235\ttest: 0.4669054\tbest: 0.4629062 (211)\ttotal: 1m 14s\tremaining: 27.5s\n",
      "730:\tlearn: 0.3550817\ttest: 0.4668180\tbest: 0.4629062 (211)\ttotal: 1m 14s\tremaining: 27.4s\n",
      "731:\tlearn: 0.3550535\ttest: 0.4668425\tbest: 0.4629062 (211)\ttotal: 1m 14s\tremaining: 27.4s\n",
      "732:\tlearn: 0.3549898\ttest: 0.4669739\tbest: 0.4629062 (211)\ttotal: 1m 14s\tremaining: 27.3s\n",
      "733:\tlearn: 0.3549828\ttest: 0.4669824\tbest: 0.4629062 (211)\ttotal: 1m 14s\tremaining: 27.2s\n",
      "734:\tlearn: 0.3548457\ttest: 0.4672554\tbest: 0.4629062 (211)\ttotal: 1m 15s\tremaining: 27.1s\n",
      "735:\tlearn: 0.3548153\ttest: 0.4672478\tbest: 0.4629062 (211)\ttotal: 1m 15s\tremaining: 27s\n",
      "736:\tlearn: 0.3546664\ttest: 0.4672379\tbest: 0.4629062 (211)\ttotal: 1m 15s\tremaining: 26.9s\n",
      "737:\tlearn: 0.3546243\ttest: 0.4672317\tbest: 0.4629062 (211)\ttotal: 1m 15s\tremaining: 26.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738:\tlearn: 0.3545760\ttest: 0.4672995\tbest: 0.4629062 (211)\ttotal: 1m 15s\tremaining: 26.7s\n",
      "739:\tlearn: 0.3545714\ttest: 0.4672802\tbest: 0.4629062 (211)\ttotal: 1m 15s\tremaining: 26.6s\n",
      "740:\tlearn: 0.3545119\ttest: 0.4672914\tbest: 0.4629062 (211)\ttotal: 1m 15s\tremaining: 26.5s\n",
      "741:\tlearn: 0.3544419\ttest: 0.4672688\tbest: 0.4629062 (211)\ttotal: 1m 15s\tremaining: 26.4s\n",
      "742:\tlearn: 0.3543125\ttest: 0.4673239\tbest: 0.4629062 (211)\ttotal: 1m 16s\tremaining: 26.3s\n",
      "743:\tlearn: 0.3540553\ttest: 0.4673286\tbest: 0.4629062 (211)\ttotal: 1m 16s\tremaining: 26.2s\n",
      "744:\tlearn: 0.3540073\ttest: 0.4673333\tbest: 0.4629062 (211)\ttotal: 1m 16s\tremaining: 26.1s\n",
      "745:\tlearn: 0.3536085\ttest: 0.4671180\tbest: 0.4629062 (211)\ttotal: 1m 16s\tremaining: 26s\n",
      "746:\tlearn: 0.3534887\ttest: 0.4673300\tbest: 0.4629062 (211)\ttotal: 1m 16s\tremaining: 25.9s\n",
      "747:\tlearn: 0.3534510\ttest: 0.4673183\tbest: 0.4629062 (211)\ttotal: 1m 16s\tremaining: 25.8s\n",
      "748:\tlearn: 0.3534392\ttest: 0.4673188\tbest: 0.4629062 (211)\ttotal: 1m 16s\tremaining: 25.7s\n",
      "749:\tlearn: 0.3533056\ttest: 0.4673028\tbest: 0.4629062 (211)\ttotal: 1m 16s\tremaining: 25.6s\n",
      "750:\tlearn: 0.3532579\ttest: 0.4673409\tbest: 0.4629062 (211)\ttotal: 1m 16s\tremaining: 25.5s\n",
      "751:\tlearn: 0.3532547\ttest: 0.4673412\tbest: 0.4629062 (211)\ttotal: 1m 16s\tremaining: 25.4s\n",
      "752:\tlearn: 0.3529093\ttest: 0.4673649\tbest: 0.4629062 (211)\ttotal: 1m 17s\tremaining: 25.3s\n",
      "753:\tlearn: 0.3528928\ttest: 0.4673659\tbest: 0.4629062 (211)\ttotal: 1m 17s\tremaining: 25.2s\n",
      "754:\tlearn: 0.3528796\ttest: 0.4673464\tbest: 0.4629062 (211)\ttotal: 1m 17s\tremaining: 25.1s\n",
      "755:\tlearn: 0.3528435\ttest: 0.4673253\tbest: 0.4629062 (211)\ttotal: 1m 17s\tremaining: 25s\n",
      "756:\tlearn: 0.3527688\ttest: 0.4674061\tbest: 0.4629062 (211)\ttotal: 1m 17s\tremaining: 24.9s\n",
      "757:\tlearn: 0.3527677\ttest: 0.4674003\tbest: 0.4629062 (211)\ttotal: 1m 17s\tremaining: 24.8s\n",
      "758:\tlearn: 0.3527344\ttest: 0.4673832\tbest: 0.4629062 (211)\ttotal: 1m 17s\tremaining: 24.7s\n",
      "759:\tlearn: 0.3527170\ttest: 0.4673890\tbest: 0.4629062 (211)\ttotal: 1m 17s\tremaining: 24.6s\n",
      "760:\tlearn: 0.3526648\ttest: 0.4674748\tbest: 0.4629062 (211)\ttotal: 1m 17s\tremaining: 24.5s\n",
      "761:\tlearn: 0.3526309\ttest: 0.4675089\tbest: 0.4629062 (211)\ttotal: 1m 18s\tremaining: 24.4s\n",
      "762:\tlearn: 0.3525438\ttest: 0.4674794\tbest: 0.4629062 (211)\ttotal: 1m 18s\tremaining: 24.3s\n",
      "763:\tlearn: 0.3524377\ttest: 0.4676945\tbest: 0.4629062 (211)\ttotal: 1m 18s\tremaining: 24.2s\n",
      "764:\tlearn: 0.3523115\ttest: 0.4677512\tbest: 0.4629062 (211)\ttotal: 1m 18s\tremaining: 24.1s\n",
      "765:\tlearn: 0.3523100\ttest: 0.4677466\tbest: 0.4629062 (211)\ttotal: 1m 18s\tremaining: 23.9s\n",
      "766:\tlearn: 0.3522787\ttest: 0.4677622\tbest: 0.4629062 (211)\ttotal: 1m 18s\tremaining: 23.9s\n",
      "767:\tlearn: 0.3522433\ttest: 0.4677805\tbest: 0.4629062 (211)\ttotal: 1m 18s\tremaining: 23.8s\n",
      "768:\tlearn: 0.3522304\ttest: 0.4678158\tbest: 0.4629062 (211)\ttotal: 1m 18s\tremaining: 23.7s\n",
      "769:\tlearn: 0.3520498\ttest: 0.4678181\tbest: 0.4629062 (211)\ttotal: 1m 19s\tremaining: 23.6s\n",
      "770:\tlearn: 0.3520208\ttest: 0.4678348\tbest: 0.4629062 (211)\ttotal: 1m 19s\tremaining: 23.5s\n",
      "771:\tlearn: 0.3519144\ttest: 0.4678264\tbest: 0.4629062 (211)\ttotal: 1m 19s\tremaining: 23.4s\n",
      "772:\tlearn: 0.3517409\ttest: 0.4678106\tbest: 0.4629062 (211)\ttotal: 1m 19s\tremaining: 23.3s\n",
      "773:\tlearn: 0.3517231\ttest: 0.4677768\tbest: 0.4629062 (211)\ttotal: 1m 19s\tremaining: 23.2s\n",
      "774:\tlearn: 0.3516687\ttest: 0.4677520\tbest: 0.4629062 (211)\ttotal: 1m 19s\tremaining: 23.1s\n",
      "775:\tlearn: 0.3515920\ttest: 0.4676461\tbest: 0.4629062 (211)\ttotal: 1m 19s\tremaining: 23s\n",
      "776:\tlearn: 0.3515751\ttest: 0.4676627\tbest: 0.4629062 (211)\ttotal: 1m 19s\tremaining: 22.9s\n",
      "777:\tlearn: 0.3515197\ttest: 0.4676946\tbest: 0.4629062 (211)\ttotal: 1m 19s\tremaining: 22.8s\n",
      "778:\tlearn: 0.3514810\ttest: 0.4676676\tbest: 0.4629062 (211)\ttotal: 1m 19s\tremaining: 22.7s\n",
      "779:\tlearn: 0.3512382\ttest: 0.4673725\tbest: 0.4629062 (211)\ttotal: 1m 19s\tremaining: 22.6s\n",
      "780:\tlearn: 0.3512304\ttest: 0.4673687\tbest: 0.4629062 (211)\ttotal: 1m 20s\tremaining: 22.4s\n",
      "781:\tlearn: 0.3512237\ttest: 0.4673567\tbest: 0.4629062 (211)\ttotal: 1m 20s\tremaining: 22.4s\n",
      "782:\tlearn: 0.3511882\ttest: 0.4673088\tbest: 0.4629062 (211)\ttotal: 1m 20s\tremaining: 22.2s\n",
      "783:\tlearn: 0.3511872\ttest: 0.4673051\tbest: 0.4629062 (211)\ttotal: 1m 20s\tremaining: 22.1s\n",
      "784:\tlearn: 0.3511817\ttest: 0.4672699\tbest: 0.4629062 (211)\ttotal: 1m 20s\tremaining: 22s\n",
      "785:\tlearn: 0.3511808\ttest: 0.4672693\tbest: 0.4629062 (211)\ttotal: 1m 20s\tremaining: 21.9s\n",
      "786:\tlearn: 0.3511362\ttest: 0.4672803\tbest: 0.4629062 (211)\ttotal: 1m 20s\tremaining: 21.8s\n",
      "787:\tlearn: 0.3511202\ttest: 0.4672903\tbest: 0.4629062 (211)\ttotal: 1m 20s\tremaining: 21.7s\n",
      "788:\tlearn: 0.3511036\ttest: 0.4672893\tbest: 0.4629062 (211)\ttotal: 1m 20s\tremaining: 21.6s\n",
      "789:\tlearn: 0.3510393\ttest: 0.4673609\tbest: 0.4629062 (211)\ttotal: 1m 20s\tremaining: 21.5s\n",
      "790:\tlearn: 0.3508731\ttest: 0.4674129\tbest: 0.4629062 (211)\ttotal: 1m 20s\tremaining: 21.4s\n",
      "791:\tlearn: 0.3506445\ttest: 0.4674316\tbest: 0.4629062 (211)\ttotal: 1m 21s\tremaining: 21.3s\n",
      "792:\tlearn: 0.3505377\ttest: 0.4674704\tbest: 0.4629062 (211)\ttotal: 1m 21s\tremaining: 21.2s\n",
      "793:\tlearn: 0.3505360\ttest: 0.4674705\tbest: 0.4629062 (211)\ttotal: 1m 21s\tremaining: 21.1s\n",
      "794:\tlearn: 0.3505227\ttest: 0.4674828\tbest: 0.4629062 (211)\ttotal: 1m 21s\tremaining: 21s\n",
      "795:\tlearn: 0.3505205\ttest: 0.4674789\tbest: 0.4629062 (211)\ttotal: 1m 21s\tremaining: 20.9s\n",
      "796:\tlearn: 0.3504905\ttest: 0.4674489\tbest: 0.4629062 (211)\ttotal: 1m 21s\tremaining: 20.8s\n",
      "797:\tlearn: 0.3504893\ttest: 0.4674414\tbest: 0.4629062 (211)\ttotal: 1m 21s\tremaining: 20.6s\n",
      "798:\tlearn: 0.3503784\ttest: 0.4675698\tbest: 0.4629062 (211)\ttotal: 1m 21s\tremaining: 20.5s\n",
      "799:\tlearn: 0.3503771\ttest: 0.4675681\tbest: 0.4629062 (211)\ttotal: 1m 21s\tremaining: 20.4s\n",
      "800:\tlearn: 0.3503661\ttest: 0.4675992\tbest: 0.4629062 (211)\ttotal: 1m 21s\tremaining: 20.3s\n",
      "801:\tlearn: 0.3503647\ttest: 0.4675994\tbest: 0.4629062 (211)\ttotal: 1m 21s\tremaining: 20.2s\n",
      "802:\tlearn: 0.3503632\ttest: 0.4675993\tbest: 0.4629062 (211)\ttotal: 1m 21s\tremaining: 20.1s\n",
      "803:\tlearn: 0.3503622\ttest: 0.4675955\tbest: 0.4629062 (211)\ttotal: 1m 22s\tremaining: 20s\n",
      "804:\tlearn: 0.3503527\ttest: 0.4675743\tbest: 0.4629062 (211)\ttotal: 1m 22s\tremaining: 19.9s\n",
      "805:\tlearn: 0.3503517\ttest: 0.4675746\tbest: 0.4629062 (211)\ttotal: 1m 22s\tremaining: 19.8s\n",
      "806:\tlearn: 0.3503510\ttest: 0.4675748\tbest: 0.4629062 (211)\ttotal: 1m 22s\tremaining: 19.7s\n",
      "807:\tlearn: 0.3503502\ttest: 0.4675735\tbest: 0.4629062 (211)\ttotal: 1m 22s\tremaining: 19.6s\n",
      "808:\tlearn: 0.3503499\ttest: 0.4675765\tbest: 0.4629062 (211)\ttotal: 1m 22s\tremaining: 19.5s\n",
      "809:\tlearn: 0.3503341\ttest: 0.4675623\tbest: 0.4629062 (211)\ttotal: 1m 22s\tremaining: 19.4s\n",
      "810:\tlearn: 0.3503340\ttest: 0.4675640\tbest: 0.4629062 (211)\ttotal: 1m 22s\tremaining: 19.3s\n",
      "811:\tlearn: 0.3503147\ttest: 0.4675457\tbest: 0.4629062 (211)\ttotal: 1m 22s\tremaining: 19.2s\n",
      "812:\tlearn: 0.3502724\ttest: 0.4675694\tbest: 0.4629062 (211)\ttotal: 1m 22s\tremaining: 19.1s\n",
      "813:\tlearn: 0.3502721\ttest: 0.4675758\tbest: 0.4629062 (211)\ttotal: 1m 22s\tremaining: 18.9s\n",
      "814:\tlearn: 0.3502706\ttest: 0.4675791\tbest: 0.4629062 (211)\ttotal: 1m 22s\tremaining: 18.8s\n",
      "815:\tlearn: 0.3502690\ttest: 0.4675864\tbest: 0.4629062 (211)\ttotal: 1m 23s\tremaining: 18.7s\n",
      "816:\tlearn: 0.3501649\ttest: 0.4676715\tbest: 0.4629062 (211)\ttotal: 1m 23s\tremaining: 18.6s\n",
      "817:\tlearn: 0.3501477\ttest: 0.4676752\tbest: 0.4629062 (211)\ttotal: 1m 23s\tremaining: 18.5s\n",
      "818:\tlearn: 0.3501473\ttest: 0.4676798\tbest: 0.4629062 (211)\ttotal: 1m 23s\tremaining: 18.4s\n",
      "819:\tlearn: 0.3500967\ttest: 0.4677981\tbest: 0.4629062 (211)\ttotal: 1m 23s\tremaining: 18.3s\n",
      "820:\tlearn: 0.3500227\ttest: 0.4676449\tbest: 0.4629062 (211)\ttotal: 1m 23s\tremaining: 18.2s\n",
      "821:\tlearn: 0.3496313\ttest: 0.4674835\tbest: 0.4629062 (211)\ttotal: 1m 23s\tremaining: 18.1s\n",
      "822:\tlearn: 0.3495597\ttest: 0.4673891\tbest: 0.4629062 (211)\ttotal: 1m 23s\tremaining: 18s\n",
      "823:\tlearn: 0.3495394\ttest: 0.4674206\tbest: 0.4629062 (211)\ttotal: 1m 23s\tremaining: 17.9s\n",
      "824:\tlearn: 0.3494971\ttest: 0.4674648\tbest: 0.4629062 (211)\ttotal: 1m 24s\tremaining: 17.8s\n",
      "825:\tlearn: 0.3494956\ttest: 0.4674615\tbest: 0.4629062 (211)\ttotal: 1m 24s\tremaining: 17.7s\n",
      "826:\tlearn: 0.3492896\ttest: 0.4675470\tbest: 0.4629062 (211)\ttotal: 1m 24s\tremaining: 17.6s\n",
      "827:\tlearn: 0.3492644\ttest: 0.4675498\tbest: 0.4629062 (211)\ttotal: 1m 24s\tremaining: 17.5s\n",
      "828:\tlearn: 0.3492552\ttest: 0.4675536\tbest: 0.4629062 (211)\ttotal: 1m 24s\tremaining: 17.4s\n",
      "829:\tlearn: 0.3491469\ttest: 0.4676938\tbest: 0.4629062 (211)\ttotal: 1m 24s\tremaining: 17.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "830:\tlearn: 0.3491255\ttest: 0.4676898\tbest: 0.4629062 (211)\ttotal: 1m 24s\tremaining: 17.2s\n",
      "831:\tlearn: 0.3491249\ttest: 0.4676910\tbest: 0.4629062 (211)\ttotal: 1m 24s\tremaining: 17.1s\n",
      "832:\tlearn: 0.3490673\ttest: 0.4676802\tbest: 0.4629062 (211)\ttotal: 1m 24s\tremaining: 17s\n",
      "833:\tlearn: 0.3490383\ttest: 0.4676648\tbest: 0.4629062 (211)\ttotal: 1m 24s\tremaining: 16.9s\n",
      "834:\tlearn: 0.3490095\ttest: 0.4676037\tbest: 0.4629062 (211)\ttotal: 1m 24s\tremaining: 16.8s\n",
      "835:\tlearn: 0.3489497\ttest: 0.4676512\tbest: 0.4629062 (211)\ttotal: 1m 25s\tremaining: 16.7s\n",
      "836:\tlearn: 0.3489496\ttest: 0.4676552\tbest: 0.4629062 (211)\ttotal: 1m 25s\tremaining: 16.6s\n",
      "837:\tlearn: 0.3488097\ttest: 0.4677163\tbest: 0.4629062 (211)\ttotal: 1m 25s\tremaining: 16.5s\n",
      "838:\tlearn: 0.3488089\ttest: 0.4677191\tbest: 0.4629062 (211)\ttotal: 1m 25s\tremaining: 16.4s\n",
      "839:\tlearn: 0.3488033\ttest: 0.4677118\tbest: 0.4629062 (211)\ttotal: 1m 25s\tremaining: 16.3s\n",
      "840:\tlearn: 0.3487212\ttest: 0.4676249\tbest: 0.4629062 (211)\ttotal: 1m 25s\tremaining: 16.2s\n",
      "841:\tlearn: 0.3487010\ttest: 0.4676606\tbest: 0.4629062 (211)\ttotal: 1m 25s\tremaining: 16s\n",
      "842:\tlearn: 0.3487006\ttest: 0.4676613\tbest: 0.4629062 (211)\ttotal: 1m 25s\tremaining: 15.9s\n",
      "843:\tlearn: 0.3486918\ttest: 0.4676811\tbest: 0.4629062 (211)\ttotal: 1m 25s\tremaining: 15.8s\n",
      "844:\tlearn: 0.3486915\ttest: 0.4676819\tbest: 0.4629062 (211)\ttotal: 1m 25s\tremaining: 15.7s\n",
      "845:\tlearn: 0.3486361\ttest: 0.4677686\tbest: 0.4629062 (211)\ttotal: 1m 25s\tremaining: 15.6s\n",
      "846:\tlearn: 0.3486139\ttest: 0.4677607\tbest: 0.4629062 (211)\ttotal: 1m 25s\tremaining: 15.5s\n",
      "847:\tlearn: 0.3485844\ttest: 0.4677798\tbest: 0.4629062 (211)\ttotal: 1m 26s\tremaining: 15.4s\n",
      "848:\tlearn: 0.3485110\ttest: 0.4678090\tbest: 0.4629062 (211)\ttotal: 1m 26s\tremaining: 15.3s\n",
      "849:\tlearn: 0.3485062\ttest: 0.4678089\tbest: 0.4629062 (211)\ttotal: 1m 26s\tremaining: 15.2s\n",
      "850:\tlearn: 0.3485053\ttest: 0.4678033\tbest: 0.4629062 (211)\ttotal: 1m 26s\tremaining: 15.1s\n",
      "851:\tlearn: 0.3484961\ttest: 0.4678039\tbest: 0.4629062 (211)\ttotal: 1m 26s\tremaining: 15s\n",
      "852:\tlearn: 0.3484825\ttest: 0.4678059\tbest: 0.4629062 (211)\ttotal: 1m 26s\tremaining: 14.9s\n",
      "853:\tlearn: 0.3484324\ttest: 0.4678431\tbest: 0.4629062 (211)\ttotal: 1m 26s\tremaining: 14.8s\n",
      "854:\tlearn: 0.3483272\ttest: 0.4677692\tbest: 0.4629062 (211)\ttotal: 1m 26s\tremaining: 14.7s\n",
      "855:\tlearn: 0.3483269\ttest: 0.4677675\tbest: 0.4629062 (211)\ttotal: 1m 26s\tremaining: 14.6s\n",
      "856:\tlearn: 0.3480292\ttest: 0.4675919\tbest: 0.4629062 (211)\ttotal: 1m 26s\tremaining: 14.5s\n",
      "857:\tlearn: 0.3478909\ttest: 0.4675737\tbest: 0.4629062 (211)\ttotal: 1m 26s\tremaining: 14.4s\n",
      "858:\tlearn: 0.3478703\ttest: 0.4676231\tbest: 0.4629062 (211)\ttotal: 1m 26s\tremaining: 14.3s\n",
      "859:\tlearn: 0.3478625\ttest: 0.4676429\tbest: 0.4629062 (211)\ttotal: 1m 27s\tremaining: 14.2s\n",
      "860:\tlearn: 0.3478578\ttest: 0.4676434\tbest: 0.4629062 (211)\ttotal: 1m 27s\tremaining: 14.1s\n",
      "861:\tlearn: 0.3477995\ttest: 0.4676453\tbest: 0.4629062 (211)\ttotal: 1m 27s\tremaining: 14s\n",
      "862:\tlearn: 0.3477795\ttest: 0.4677155\tbest: 0.4629062 (211)\ttotal: 1m 27s\tremaining: 13.9s\n",
      "863:\tlearn: 0.3477709\ttest: 0.4677061\tbest: 0.4629062 (211)\ttotal: 1m 27s\tremaining: 13.8s\n",
      "864:\tlearn: 0.3477098\ttest: 0.4677264\tbest: 0.4629062 (211)\ttotal: 1m 27s\tremaining: 13.7s\n",
      "865:\tlearn: 0.3476491\ttest: 0.4677175\tbest: 0.4629062 (211)\ttotal: 1m 27s\tremaining: 13.6s\n",
      "866:\tlearn: 0.3475913\ttest: 0.4676912\tbest: 0.4629062 (211)\ttotal: 1m 27s\tremaining: 13.5s\n",
      "867:\tlearn: 0.3474647\ttest: 0.4677907\tbest: 0.4629062 (211)\ttotal: 1m 27s\tremaining: 13.4s\n",
      "868:\tlearn: 0.3474496\ttest: 0.4677758\tbest: 0.4629062 (211)\ttotal: 1m 27s\tremaining: 13.2s\n",
      "869:\tlearn: 0.3474484\ttest: 0.4677719\tbest: 0.4629062 (211)\ttotal: 1m 27s\tremaining: 13.1s\n",
      "870:\tlearn: 0.3474466\ttest: 0.4677683\tbest: 0.4629062 (211)\ttotal: 1m 28s\tremaining: 13s\n",
      "871:\tlearn: 0.3474417\ttest: 0.4677592\tbest: 0.4629062 (211)\ttotal: 1m 28s\tremaining: 12.9s\n",
      "872:\tlearn: 0.3472656\ttest: 0.4678194\tbest: 0.4629062 (211)\ttotal: 1m 28s\tremaining: 12.8s\n",
      "873:\tlearn: 0.3472653\ttest: 0.4678262\tbest: 0.4629062 (211)\ttotal: 1m 28s\tremaining: 12.7s\n",
      "874:\tlearn: 0.3471188\ttest: 0.4679180\tbest: 0.4629062 (211)\ttotal: 1m 28s\tremaining: 12.6s\n",
      "875:\tlearn: 0.3470980\ttest: 0.4679499\tbest: 0.4629062 (211)\ttotal: 1m 28s\tremaining: 12.5s\n",
      "876:\tlearn: 0.3470574\ttest: 0.4679793\tbest: 0.4629062 (211)\ttotal: 1m 28s\tremaining: 12.4s\n",
      "877:\tlearn: 0.3469843\ttest: 0.4679296\tbest: 0.4629062 (211)\ttotal: 1m 28s\tremaining: 12.3s\n",
      "878:\tlearn: 0.3469625\ttest: 0.4679132\tbest: 0.4629062 (211)\ttotal: 1m 28s\tremaining: 12.2s\n",
      "879:\tlearn: 0.3468288\ttest: 0.4679358\tbest: 0.4629062 (211)\ttotal: 1m 28s\tremaining: 12.1s\n",
      "880:\tlearn: 0.3467203\ttest: 0.4678649\tbest: 0.4629062 (211)\ttotal: 1m 28s\tremaining: 12s\n",
      "881:\tlearn: 0.3467194\ttest: 0.4678693\tbest: 0.4629062 (211)\ttotal: 1m 29s\tremaining: 11.9s\n",
      "882:\tlearn: 0.3466250\ttest: 0.4677781\tbest: 0.4629062 (211)\ttotal: 1m 29s\tremaining: 11.8s\n",
      "883:\tlearn: 0.3466247\ttest: 0.4677839\tbest: 0.4629062 (211)\ttotal: 1m 29s\tremaining: 11.7s\n",
      "884:\tlearn: 0.3466246\ttest: 0.4677863\tbest: 0.4629062 (211)\ttotal: 1m 29s\tremaining: 11.6s\n",
      "885:\tlearn: 0.3464404\ttest: 0.4678669\tbest: 0.4629062 (211)\ttotal: 1m 29s\tremaining: 11.5s\n",
      "886:\tlearn: 0.3464091\ttest: 0.4679733\tbest: 0.4629062 (211)\ttotal: 1m 29s\tremaining: 11.4s\n",
      "887:\tlearn: 0.3462678\ttest: 0.4679104\tbest: 0.4629062 (211)\ttotal: 1m 29s\tremaining: 11.3s\n",
      "888:\tlearn: 0.3461379\ttest: 0.4679803\tbest: 0.4629062 (211)\ttotal: 1m 29s\tremaining: 11.2s\n",
      "889:\tlearn: 0.3461080\ttest: 0.4679909\tbest: 0.4629062 (211)\ttotal: 1m 29s\tremaining: 11.1s\n",
      "890:\tlearn: 0.3459306\ttest: 0.4679797\tbest: 0.4629062 (211)\ttotal: 1m 29s\tremaining: 11s\n",
      "891:\tlearn: 0.3456158\ttest: 0.4678667\tbest: 0.4629062 (211)\ttotal: 1m 29s\tremaining: 10.9s\n",
      "892:\tlearn: 0.3455999\ttest: 0.4678826\tbest: 0.4629062 (211)\ttotal: 1m 29s\tremaining: 10.8s\n",
      "893:\tlearn: 0.3455896\ttest: 0.4678850\tbest: 0.4629062 (211)\ttotal: 1m 30s\tremaining: 10.7s\n",
      "894:\tlearn: 0.3455653\ttest: 0.4679817\tbest: 0.4629062 (211)\ttotal: 1m 30s\tremaining: 10.6s\n",
      "895:\tlearn: 0.3453815\ttest: 0.4679580\tbest: 0.4629062 (211)\ttotal: 1m 30s\tremaining: 10.5s\n",
      "896:\tlearn: 0.3453262\ttest: 0.4679178\tbest: 0.4629062 (211)\ttotal: 1m 30s\tremaining: 10.4s\n",
      "897:\tlearn: 0.3451670\ttest: 0.4678201\tbest: 0.4629062 (211)\ttotal: 1m 30s\tremaining: 10.3s\n",
      "898:\tlearn: 0.3451328\ttest: 0.4677704\tbest: 0.4629062 (211)\ttotal: 1m 30s\tremaining: 10.2s\n",
      "899:\tlearn: 0.3450927\ttest: 0.4678156\tbest: 0.4629062 (211)\ttotal: 1m 30s\tremaining: 10.1s\n",
      "900:\tlearn: 0.3450921\ttest: 0.4678127\tbest: 0.4629062 (211)\ttotal: 1m 30s\tremaining: 9.96s\n",
      "901:\tlearn: 0.3450281\ttest: 0.4680066\tbest: 0.4629062 (211)\ttotal: 1m 30s\tremaining: 9.86s\n",
      "902:\tlearn: 0.3449677\ttest: 0.4679716\tbest: 0.4629062 (211)\ttotal: 1m 30s\tremaining: 9.76s\n",
      "903:\tlearn: 0.3449562\ttest: 0.4679662\tbest: 0.4629062 (211)\ttotal: 1m 30s\tremaining: 9.66s\n",
      "904:\tlearn: 0.3449174\ttest: 0.4680690\tbest: 0.4629062 (211)\ttotal: 1m 31s\tremaining: 9.55s\n",
      "905:\tlearn: 0.3448607\ttest: 0.4680752\tbest: 0.4629062 (211)\ttotal: 1m 31s\tremaining: 9.46s\n",
      "906:\tlearn: 0.3447368\ttest: 0.4682538\tbest: 0.4629062 (211)\ttotal: 1m 31s\tremaining: 9.35s\n",
      "907:\tlearn: 0.3447258\ttest: 0.4682512\tbest: 0.4629062 (211)\ttotal: 1m 31s\tremaining: 9.25s\n",
      "908:\tlearn: 0.3446139\ttest: 0.4682487\tbest: 0.4629062 (211)\ttotal: 1m 31s\tremaining: 9.15s\n",
      "909:\tlearn: 0.3445824\ttest: 0.4682158\tbest: 0.4629062 (211)\ttotal: 1m 31s\tremaining: 9.05s\n",
      "910:\tlearn: 0.3445822\ttest: 0.4682201\tbest: 0.4629062 (211)\ttotal: 1m 31s\tremaining: 8.95s\n",
      "911:\tlearn: 0.3445658\ttest: 0.4683086\tbest: 0.4629062 (211)\ttotal: 1m 31s\tremaining: 8.84s\n",
      "912:\tlearn: 0.3445340\ttest: 0.4683261\tbest: 0.4629062 (211)\ttotal: 1m 31s\tremaining: 8.74s\n",
      "913:\tlearn: 0.3445087\ttest: 0.4683196\tbest: 0.4629062 (211)\ttotal: 1m 31s\tremaining: 8.64s\n",
      "914:\tlearn: 0.3444475\ttest: 0.4684144\tbest: 0.4629062 (211)\ttotal: 1m 31s\tremaining: 8.54s\n",
      "915:\tlearn: 0.3444393\ttest: 0.4684434\tbest: 0.4629062 (211)\ttotal: 1m 32s\tremaining: 8.44s\n",
      "916:\tlearn: 0.3443768\ttest: 0.4685037\tbest: 0.4629062 (211)\ttotal: 1m 32s\tremaining: 8.34s\n",
      "917:\tlearn: 0.3442662\ttest: 0.4685375\tbest: 0.4629062 (211)\ttotal: 1m 32s\tremaining: 8.24s\n",
      "918:\tlearn: 0.3440849\ttest: 0.4685841\tbest: 0.4629062 (211)\ttotal: 1m 32s\tremaining: 8.14s\n",
      "919:\tlearn: 0.3438937\ttest: 0.4687410\tbest: 0.4629062 (211)\ttotal: 1m 32s\tremaining: 8.04s\n",
      "920:\tlearn: 0.3438184\ttest: 0.4687961\tbest: 0.4629062 (211)\ttotal: 1m 32s\tremaining: 7.93s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921:\tlearn: 0.3437622\ttest: 0.4688189\tbest: 0.4629062 (211)\ttotal: 1m 32s\tremaining: 7.83s\n",
      "922:\tlearn: 0.3437553\ttest: 0.4688164\tbest: 0.4629062 (211)\ttotal: 1m 32s\tremaining: 7.73s\n",
      "923:\tlearn: 0.3437376\ttest: 0.4687897\tbest: 0.4629062 (211)\ttotal: 1m 32s\tremaining: 7.63s\n",
      "924:\tlearn: 0.3436969\ttest: 0.4688435\tbest: 0.4629062 (211)\ttotal: 1m 32s\tremaining: 7.53s\n",
      "925:\tlearn: 0.3436132\ttest: 0.4687311\tbest: 0.4629062 (211)\ttotal: 1m 32s\tremaining: 7.43s\n",
      "926:\tlearn: 0.3435493\ttest: 0.4687178\tbest: 0.4629062 (211)\ttotal: 1m 33s\tremaining: 7.33s\n",
      "927:\tlearn: 0.3435193\ttest: 0.4687858\tbest: 0.4629062 (211)\ttotal: 1m 33s\tremaining: 7.23s\n",
      "928:\tlearn: 0.3434729\ttest: 0.4687662\tbest: 0.4629062 (211)\ttotal: 1m 33s\tremaining: 7.13s\n",
      "929:\tlearn: 0.3433627\ttest: 0.4687391\tbest: 0.4629062 (211)\ttotal: 1m 33s\tremaining: 7.02s\n",
      "930:\tlearn: 0.3433620\ttest: 0.4687350\tbest: 0.4629062 (211)\ttotal: 1m 33s\tremaining: 6.92s\n",
      "931:\tlearn: 0.3433553\ttest: 0.4687298\tbest: 0.4629062 (211)\ttotal: 1m 33s\tremaining: 6.82s\n",
      "932:\tlearn: 0.3433522\ttest: 0.4687462\tbest: 0.4629062 (211)\ttotal: 1m 33s\tremaining: 6.72s\n",
      "933:\tlearn: 0.3433144\ttest: 0.4687632\tbest: 0.4629062 (211)\ttotal: 1m 33s\tremaining: 6.62s\n",
      "934:\tlearn: 0.3430970\ttest: 0.4686610\tbest: 0.4629062 (211)\ttotal: 1m 33s\tremaining: 6.52s\n",
      "935:\tlearn: 0.3430964\ttest: 0.4686613\tbest: 0.4629062 (211)\ttotal: 1m 33s\tremaining: 6.42s\n",
      "936:\tlearn: 0.3430819\ttest: 0.4686666\tbest: 0.4629062 (211)\ttotal: 1m 34s\tremaining: 6.32s\n",
      "937:\tlearn: 0.3430709\ttest: 0.4686536\tbest: 0.4629062 (211)\ttotal: 1m 34s\tremaining: 6.22s\n",
      "938:\tlearn: 0.3430451\ttest: 0.4686332\tbest: 0.4629062 (211)\ttotal: 1m 34s\tremaining: 6.12s\n",
      "939:\tlearn: 0.3430343\ttest: 0.4686178\tbest: 0.4629062 (211)\ttotal: 1m 34s\tremaining: 6.02s\n",
      "940:\tlearn: 0.3430220\ttest: 0.4686163\tbest: 0.4629062 (211)\ttotal: 1m 34s\tremaining: 5.92s\n",
      "941:\tlearn: 0.3430192\ttest: 0.4686148\tbest: 0.4629062 (211)\ttotal: 1m 34s\tremaining: 5.82s\n",
      "942:\tlearn: 0.3429874\ttest: 0.4686527\tbest: 0.4629062 (211)\ttotal: 1m 34s\tremaining: 5.72s\n",
      "943:\tlearn: 0.3429473\ttest: 0.4686364\tbest: 0.4629062 (211)\ttotal: 1m 34s\tremaining: 5.62s\n",
      "944:\tlearn: 0.3429114\ttest: 0.4686274\tbest: 0.4629062 (211)\ttotal: 1m 34s\tremaining: 5.52s\n",
      "945:\tlearn: 0.3429014\ttest: 0.4686284\tbest: 0.4629062 (211)\ttotal: 1m 34s\tremaining: 5.42s\n",
      "946:\tlearn: 0.3428474\ttest: 0.4686277\tbest: 0.4629062 (211)\ttotal: 1m 35s\tremaining: 5.32s\n",
      "947:\tlearn: 0.3426838\ttest: 0.4687917\tbest: 0.4629062 (211)\ttotal: 1m 35s\tremaining: 5.22s\n",
      "948:\tlearn: 0.3426834\ttest: 0.4687909\tbest: 0.4629062 (211)\ttotal: 1m 35s\tremaining: 5.12s\n",
      "949:\tlearn: 0.3426829\ttest: 0.4687914\tbest: 0.4629062 (211)\ttotal: 1m 35s\tremaining: 5.01s\n",
      "950:\tlearn: 0.3426757\ttest: 0.4688050\tbest: 0.4629062 (211)\ttotal: 1m 35s\tremaining: 4.91s\n",
      "951:\tlearn: 0.3426038\ttest: 0.4688071\tbest: 0.4629062 (211)\ttotal: 1m 35s\tremaining: 4.81s\n",
      "952:\tlearn: 0.3426034\ttest: 0.4688076\tbest: 0.4629062 (211)\ttotal: 1m 35s\tremaining: 4.71s\n",
      "953:\tlearn: 0.3424952\ttest: 0.4688919\tbest: 0.4629062 (211)\ttotal: 1m 35s\tremaining: 4.61s\n",
      "954:\tlearn: 0.3424661\ttest: 0.4688949\tbest: 0.4629062 (211)\ttotal: 1m 35s\tremaining: 4.51s\n",
      "955:\tlearn: 0.3424271\ttest: 0.4689055\tbest: 0.4629062 (211)\ttotal: 1m 35s\tremaining: 4.41s\n",
      "956:\tlearn: 0.3424195\ttest: 0.4688997\tbest: 0.4629062 (211)\ttotal: 1m 35s\tremaining: 4.31s\n",
      "957:\tlearn: 0.3423829\ttest: 0.4689147\tbest: 0.4629062 (211)\ttotal: 1m 35s\tremaining: 4.21s\n",
      "958:\tlearn: 0.3423315\ttest: 0.4689435\tbest: 0.4629062 (211)\ttotal: 1m 36s\tremaining: 4.11s\n",
      "959:\tlearn: 0.3422550\ttest: 0.4689768\tbest: 0.4629062 (211)\ttotal: 1m 36s\tremaining: 4.01s\n",
      "960:\tlearn: 0.3422539\ttest: 0.4689889\tbest: 0.4629062 (211)\ttotal: 1m 36s\tremaining: 3.91s\n",
      "961:\tlearn: 0.3422210\ttest: 0.4690254\tbest: 0.4629062 (211)\ttotal: 1m 36s\tremaining: 3.81s\n",
      "962:\tlearn: 0.3421526\ttest: 0.4690570\tbest: 0.4629062 (211)\ttotal: 1m 36s\tremaining: 3.71s\n",
      "963:\tlearn: 0.3421523\ttest: 0.4690567\tbest: 0.4629062 (211)\ttotal: 1m 36s\tremaining: 3.6s\n",
      "964:\tlearn: 0.3421397\ttest: 0.4691120\tbest: 0.4629062 (211)\ttotal: 1m 36s\tremaining: 3.5s\n",
      "965:\tlearn: 0.3421344\ttest: 0.4691223\tbest: 0.4629062 (211)\ttotal: 1m 36s\tremaining: 3.4s\n",
      "966:\tlearn: 0.3420550\ttest: 0.4692338\tbest: 0.4629062 (211)\ttotal: 1m 36s\tremaining: 3.3s\n",
      "967:\tlearn: 0.3420518\ttest: 0.4692392\tbest: 0.4629062 (211)\ttotal: 1m 36s\tremaining: 3.2s\n",
      "968:\tlearn: 0.3420514\ttest: 0.4692373\tbest: 0.4629062 (211)\ttotal: 1m 36s\tremaining: 3.1s\n",
      "969:\tlearn: 0.3419161\ttest: 0.4692552\tbest: 0.4629062 (211)\ttotal: 1m 37s\tremaining: 3s\n",
      "970:\tlearn: 0.3419158\ttest: 0.4692553\tbest: 0.4629062 (211)\ttotal: 1m 37s\tremaining: 2.9s\n",
      "971:\tlearn: 0.3419154\ttest: 0.4692557\tbest: 0.4629062 (211)\ttotal: 1m 37s\tremaining: 2.8s\n",
      "972:\tlearn: 0.3419152\ttest: 0.4692540\tbest: 0.4629062 (211)\ttotal: 1m 37s\tremaining: 2.7s\n",
      "973:\tlearn: 0.3416670\ttest: 0.4689530\tbest: 0.4629062 (211)\ttotal: 1m 37s\tremaining: 2.6s\n",
      "974:\tlearn: 0.3415077\ttest: 0.4691483\tbest: 0.4629062 (211)\ttotal: 1m 37s\tremaining: 2.5s\n",
      "975:\tlearn: 0.3413369\ttest: 0.4690958\tbest: 0.4629062 (211)\ttotal: 1m 37s\tremaining: 2.4s\n",
      "976:\tlearn: 0.3412722\ttest: 0.4691283\tbest: 0.4629062 (211)\ttotal: 1m 37s\tremaining: 2.3s\n",
      "977:\tlearn: 0.3412721\ttest: 0.4691325\tbest: 0.4629062 (211)\ttotal: 1m 37s\tremaining: 2.2s\n",
      "978:\tlearn: 0.3412719\ttest: 0.4691372\tbest: 0.4629062 (211)\ttotal: 1m 37s\tremaining: 2.1s\n",
      "979:\tlearn: 0.3412438\ttest: 0.4692526\tbest: 0.4629062 (211)\ttotal: 1m 37s\tremaining: 2s\n",
      "980:\tlearn: 0.3409555\ttest: 0.4692318\tbest: 0.4629062 (211)\ttotal: 1m 37s\tremaining: 1.9s\n",
      "981:\tlearn: 0.3409331\ttest: 0.4692472\tbest: 0.4629062 (211)\ttotal: 1m 38s\tremaining: 1.8s\n",
      "982:\tlearn: 0.3409330\ttest: 0.4692487\tbest: 0.4629062 (211)\ttotal: 1m 38s\tremaining: 1.7s\n",
      "983:\tlearn: 0.3409277\ttest: 0.4692157\tbest: 0.4629062 (211)\ttotal: 1m 38s\tremaining: 1.6s\n",
      "984:\tlearn: 0.3408263\ttest: 0.4693173\tbest: 0.4629062 (211)\ttotal: 1m 38s\tremaining: 1.5s\n",
      "985:\tlearn: 0.3407075\ttest: 0.4693145\tbest: 0.4629062 (211)\ttotal: 1m 38s\tremaining: 1.4s\n",
      "986:\tlearn: 0.3407074\ttest: 0.4693154\tbest: 0.4629062 (211)\ttotal: 1m 38s\tremaining: 1.3s\n",
      "987:\tlearn: 0.3406581\ttest: 0.4692661\tbest: 0.4629062 (211)\ttotal: 1m 38s\tremaining: 1.2s\n",
      "988:\tlearn: 0.3406418\ttest: 0.4692941\tbest: 0.4629062 (211)\ttotal: 1m 38s\tremaining: 1.1s\n",
      "989:\tlearn: 0.3405569\ttest: 0.4692871\tbest: 0.4629062 (211)\ttotal: 1m 38s\tremaining: 997ms\n",
      "990:\tlearn: 0.3405567\ttest: 0.4692914\tbest: 0.4629062 (211)\ttotal: 1m 38s\tremaining: 897ms\n",
      "991:\tlearn: 0.3404892\ttest: 0.4693372\tbest: 0.4629062 (211)\ttotal: 1m 38s\tremaining: 798ms\n",
      "992:\tlearn: 0.3404739\ttest: 0.4693471\tbest: 0.4629062 (211)\ttotal: 1m 38s\tremaining: 698ms\n",
      "993:\tlearn: 0.3404324\ttest: 0.4694874\tbest: 0.4629062 (211)\ttotal: 1m 39s\tremaining: 598ms\n",
      "994:\tlearn: 0.3404143\ttest: 0.4694644\tbest: 0.4629062 (211)\ttotal: 1m 39s\tremaining: 498ms\n",
      "995:\tlearn: 0.3403986\ttest: 0.4694186\tbest: 0.4629062 (211)\ttotal: 1m 39s\tremaining: 399ms\n",
      "996:\tlearn: 0.3403449\ttest: 0.4693696\tbest: 0.4629062 (211)\ttotal: 1m 39s\tremaining: 299ms\n",
      "997:\tlearn: 0.3403375\ttest: 0.4693335\tbest: 0.4629062 (211)\ttotal: 1m 39s\tremaining: 199ms\n",
      "998:\tlearn: 0.3403352\ttest: 0.4693311\tbest: 0.4629062 (211)\ttotal: 1m 39s\tremaining: 99.6ms\n",
      "999:\tlearn: 0.3402442\ttest: 0.4694089\tbest: 0.4629062 (211)\ttotal: 1m 39s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4629062083\n",
      "bestIteration = 211\n",
      "\n",
      "Shrink model to first 212 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.793980652096023"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier()\n",
    "#categorical_features_indices = np.where(df.dtypes != np.float)[0]\n",
    "\n",
    "model.fit(X_train,y_train,cat_features=([ 0,  1, 2, 3, 4, 10]),eval_set=(X_test, y_test))\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cb.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End Notes\n",
    "Ensemble modeling can exponentially boost the performance of your model and can sometimes be the deciding factor between first place and second! In this article, we covered various ensemble learning techniques and saw how these techniques are applied in machine learning algorithms. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
