{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ANOVA Test\n",
    "An ANOVA test is a way to find out if survey or experiment results are significant. In other words, they help you to figure out if you need to reject the null hypothesis or accept the alternate hypothesis.\n",
    "\n",
    "Basically, you’re testing groups to see if there’s a difference between them.\n",
    "\n",
    "### What Does “One-Way” or “Two-Way Mean?\n",
    "One-way or two-way refers to the number of independent variables (IVs) in your Analysis of Variance test.\n",
    "\n",
    "One-way has one independent variable (with 2 levels). For example: brand of cereal,\n",
    "Two-way has two independent variables (it can have multiple levels). For example: brand of cereal, calories.\n",
    "\n",
    "### What are “Groups” or “Levels”?\n",
    "Groups or levels are different groups within the same independent variable. In the above example, your levels for “brand of cereal” might be Lucky Charms, Raisin Bran, Cornflakes — a total of three levels. Your levels for “Calories” might be: sweetened, unsweetened — a total of two levels.\n",
    "\n",
    "Let’s say you are studying if an alcoholic support group and individual counseling combined is the most effective treatment for lowering alcohol consumption. You might split the study participants into three groups or levels:\n",
    "\n",
    "Medication only,\n",
    "Medication and counseling,\n",
    "Counseling only.\n",
    "Your dependent variable would be the number of alcoholic beverages consumed per day.\n",
    "\n",
    "If your groups or levels have a hierarchical structure (each level has unique subgroups), then use a nested ANOVA for the analysis.\n",
    "\n",
    "### What Does “Replication” Mean?\n",
    "It’s whether you are replicating (i.e. duplicating) your test(s) with multiple groups. With a two way ANOVA with replication , you have two groups and individuals within that group are doing more than one thing (i.e. two groups of students from two colleges taking two tests). If you only have one group taking two tests, you would use without replication.\n",
    "\n",
    "### Types of Tests.\n",
    "There are two main types: one-way and two-way. Two-way tests can be with or without replication.\n",
    "\n",
    "One-way ANOVA between groups: used when you want to test two groups to see if there’s a difference between them.\n",
    "Two way ANOVA without replication: used when you have one group and you’re double-testing that same group. For example, you’re testing one set of individuals before and after they take a medication to see if it works or not.\n",
    "Two way ANOVA with replication: Two groups, and the members of those groups are doing more than one thing. For example, two groups of patients from different hospitals trying two different therapies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/X_train.csv')\n",
    "X_test = pd.read_csv('data/X_test.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some data exploration and ANOVA\n",
    "Let's have a look at our features and columns. And then carry out the ANOVA across measurement groups (i.e. recording sessions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>measurement_number</th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10488</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.107650</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-0.74857</td>\n",
       "      <td>2.1030</td>\n",
       "      <td>-9.7532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63434</td>\n",
       "      <td>-0.10490</td>\n",
       "      <td>-0.10600</td>\n",
       "      <td>0.067851</td>\n",
       "      <td>0.029939</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.33995</td>\n",
       "      <td>1.5064</td>\n",
       "      <td>-9.4128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10492</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.028934</td>\n",
       "      <td>-0.005978</td>\n",
       "      <td>-0.26429</td>\n",
       "      <td>1.5922</td>\n",
       "      <td>-8.7267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.75852</td>\n",
       "      <td>-0.63436</td>\n",
       "      <td>-0.10495</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>-0.013053</td>\n",
       "      <td>0.019448</td>\n",
       "      <td>-0.008974</td>\n",
       "      <td>0.42684</td>\n",
       "      <td>1.0993</td>\n",
       "      <td>-10.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.75852</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10495</td>\n",
       "      <td>-0.10596</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>-0.50969</td>\n",
       "      <td>1.4689</td>\n",
       "      <td>-10.4410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id  series_id  measurement_number  orientation_X  orientation_Y  \\\n",
       "0    0_0          0                   0       -0.75853       -0.63435   \n",
       "1    0_1          0                   1       -0.75853       -0.63434   \n",
       "2    0_2          0                   2       -0.75853       -0.63435   \n",
       "3    0_3          0                   3       -0.75852       -0.63436   \n",
       "4    0_4          0                   4       -0.75852       -0.63435   \n",
       "\n",
       "   orientation_Z  orientation_W  angular_velocity_X  angular_velocity_Y  \\\n",
       "0       -0.10488       -0.10597            0.107650            0.017561   \n",
       "1       -0.10490       -0.10600            0.067851            0.029939   \n",
       "2       -0.10492       -0.10597            0.007275            0.028934   \n",
       "3       -0.10495       -0.10597           -0.013053            0.019448   \n",
       "4       -0.10495       -0.10596            0.005135            0.007652   \n",
       "\n",
       "   angular_velocity_Z  linear_acceleration_X  linear_acceleration_Y  \\\n",
       "0            0.000767               -0.74857                 2.1030   \n",
       "1            0.003385                0.33995                 1.5064   \n",
       "2           -0.005978               -0.26429                 1.5922   \n",
       "3           -0.008974                0.42684                 1.0993   \n",
       "4            0.005245               -0.50969                 1.4689   \n",
       "\n",
       "   linear_acceleration_Z  \n",
       "0                -9.7532  \n",
       "1                -9.4128  \n",
       "2                -8.7267  \n",
       "3               -10.0960  \n",
       "4               -10.4410  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id                   0\n",
       "series_id                0\n",
       "measurement_number       0\n",
       "orientation_X            0\n",
       "orientation_Y            0\n",
       "orientation_Z            0\n",
       "orientation_W            0\n",
       "angular_velocity_X       0\n",
       "angular_velocity_Y       0\n",
       "angular_velocity_Z       0\n",
       "linear_acceleration_X    0\n",
       "linear_acceleration_Y    0\n",
       "linear_acceleration_Z    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any null values?\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>fine_concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>soft_tiles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  group_id        surface\n",
       "0          0        13  fine_concrete\n",
       "1          1        31       concrete\n",
       "2          2        20       concrete\n",
       "3          3        31       concrete\n",
       "4          4        22     soft_tiles"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['carpet', 'concrete', 'fine_concrete', 'hard_tiles',\n",
       "       'hard_tiles_large_space', 'soft_pvc', 'soft_tiles', 'tiled',\n",
       "       'wood'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# what are our surface materials i.e. targets?\n",
    "np.unique(y_train['surface'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset consists of series with a length of 128 measurements and the values from the 10 sensor channels. Every series of measurements has one target, which is a description of the surface material. Luckily, we don't have to deal with any missing values.\n",
    "\n",
    "In y_train we're furthermore given a group_id which indicates the recording session this particular series was taken. Across each session, the robot was only driving on one surface. We will make use of that information and see, if there is any variation in means across different recording sessions within the features (because of varying sensor calibrations, environment etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "surfaces = np.unique(y_train['surface'])\n",
    "y_train['surface'] = encoder.fit_transform(y_train['surface'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we have a strong variation in means across groups?\n",
    "# let's find out with pairwise t-Tests for groups with same surface\n",
    "joined = X_train.set_index('series_id').join(\n",
    "    y_train.set_index('series_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova_across_surface(surface, X):\n",
    "    # helper function to calculate anovas for group samples of surface levels\n",
    "    records = X[X.loc[:, 'surface']==surface]\n",
    "    group_nos = np.unique(records.loc[:, 'group_id'])\n",
    "    anovas = []\n",
    "    for col in records.columns:\n",
    "        samples = [list(X[X.loc[:, 'group_id'] == i][col]) for i in group_nos]\n",
    "        aov = f_oneway(*samples)\n",
    "        anovas.append(aov[0])\n",
    "        anovas.append(aov[1])\n",
    "    return anovas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all the anovas first\n",
    "anovas = dict()\n",
    "for i in range(0, 9):\n",
    "    # for each surface level\n",
    "    anovas[i] = anova_across_surface(i, joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make nice tables\n",
    "no_of_columns = 3\n",
    "new_cols = ['row_id\\t', 'measr_no', 'orien_X', 'orient_Y',\n",
    "       'orient_Z', 'orient_W', 'velocity_X',\n",
    "       'velocity_Y', 'velocity_Z', 'accel_X',\n",
    "       'accel_Y', 'accel_Z', 'group_id',\n",
    "       'surface']\n",
    "joined.columns = new_cols\n",
    "line_1 = '\\n' + '\\t\\t|%s' * no_of_columns\n",
    "line_2 = 'surface\\t\\t' + '|F\\t      p-value\\t' * no_of_columns\n",
    "line_3 = '%12.12s' + '\\t|%9.3e   %8.3f' * no_of_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t|row_id\t\t\t|measr_no\t\t|orien_X\n",
      "surface\t\t|F\t      p-value\t|F\t      p-value\t|F\t      p-value\t\n",
      "========================================================================================\n",
      "      carpet\t|9.233e+02      0.000\t|0.000e+00      1.000\t|2.623e+04      0.000\n",
      "    concrete\t|6.551e+02      0.000\t|0.000e+00      1.000\t|1.154e+05      0.000\n",
      "fine_concret\t|6.507e+02      0.000\t|0.000e+00      1.000\t|3.694e+04      0.000\n",
      "  hard_tiles\t|      nan        nan\t|      nan        nan\t|      nan        nan\n",
      "hard_tiles_l\t|8.358e+02      0.000\t|0.000e+00      1.000\t|1.055e+05      0.000\n",
      "    soft_pvc\t|8.777e+02      0.000\t|0.000e+00      1.000\t|8.220e+04      0.000\n",
      "  soft_tiles\t|1.390e+01      0.000\t|0.000e+00      1.000\t|1.477e+05      0.000\n",
      "       tiled\t|7.462e+02      0.000\t|0.000e+00      1.000\t|6.899e+04      0.000\n",
      "        wood\t|5.406e+02      0.000\t|0.000e+00      1.000\t|5.650e+03      0.000\n",
      "\n",
      "\t\t|orient_Y\t\t|orient_Z\t\t|orient_W\n",
      "surface\t\t|F\t      p-value\t|F\t      p-value\t|F\t      p-value\t\n",
      "========================================================================================\n",
      "      carpet\t|2.800e+04      0.000\t|3.202e+04      0.000\t|2.219e+04      0.000\n",
      "    concrete\t|2.135e+04      0.000\t|2.135e+04      0.000\t|1.121e+05      0.000\n",
      "fine_concret\t|5.536e+05      0.000\t|5.197e+05      0.000\t|3.810e+04      0.000\n",
      "  hard_tiles\t|      nan        nan\t|      nan        nan\t|      nan        nan\n",
      "hard_tiles_l\t|1.208e+05      0.000\t|1.259e+05      0.000\t|9.318e+04      0.000\n",
      "    soft_pvc\t|3.373e+04      0.000\t|2.908e+04      0.000\t|7.976e+04      0.000\n",
      "  soft_tiles\t|2.164e+05      0.000\t|2.120e+05      0.000\t|1.556e+05      0.000\n",
      "       tiled\t|1.448e+05      0.000\t|1.332e+05      0.000\t|7.839e+04      0.000\n",
      "        wood\t|4.812e+03      0.000\t|4.848e+03      0.000\t|5.787e+03      0.000\n",
      "\n",
      "\t\t|velocity_X\t\t|velocity_Y\t\t|velocity_Z\n",
      "surface\t\t|F\t      p-value\t|F\t      p-value\t|F\t      p-value\t\n",
      "========================================================================================\n",
      "      carpet\t|4.391e-01      0.725\t|3.253e+02      0.000\t|5.319e+02      0.000\n",
      "    concrete\t|4.628e-01      0.953\t|3.822e+02      0.000\t|8.119e+02      0.000\n",
      "fine_concret\t|1.732e+00      0.109\t|1.268e+03      0.000\t|1.884e+03      0.000\n",
      "  hard_tiles\t|      nan        nan\t|      nan        nan\t|      nan        nan\n",
      "hard_tiles_l\t|1.563e-01      0.960\t|2.568e+02      0.000\t|7.548e+02      0.000\n",
      "    soft_pvc\t|1.238e+01      0.000\t|9.504e+02      0.000\t|1.387e+03      0.000\n",
      "  soft_tiles\t|3.556e+00      0.003\t|2.750e+03      0.000\t|3.287e+03      0.000\n",
      "       tiled\t|4.082e-01      0.917\t|4.327e+02      0.000\t|1.229e+03      0.000\n",
      "        wood\t|1.264e+01      0.000\t|6.123e+03      0.000\t|8.017e+03      0.000\n",
      "\n",
      "\t\t|accel_X\t\t|accel_Y\t\t|accel_Z\n",
      "surface\t\t|F\t      p-value\t|F\t      p-value\t|F\t      p-value\t\n",
      "========================================================================================\n",
      "      carpet\t|4.354e+00      0.005\t|5.641e+00      0.001\t|7.546e-01      0.519\n",
      "    concrete\t|1.326e+00      0.182\t|1.487e+00      0.106\t|1.145e-01      1.000\n",
      "fine_concret\t|1.018e+01      0.000\t|4.371e+00      0.000\t|2.703e-01      0.951\n",
      "  hard_tiles\t|      nan        nan\t|      nan        nan\t|      nan        nan\n",
      "hard_tiles_l\t|2.809e+00      0.024\t|2.300e+00      0.056\t|7.986e-02      0.989\n",
      "    soft_pvc\t|1.400e+01      0.000\t|2.190e+02      0.000\t|1.941e+01      0.000\n",
      "  soft_tiles\t|4.736e+01      0.000\t|1.042e+01      0.000\t|2.592e+00      0.024\n",
      "       tiled\t|3.135e+00      0.002\t|2.478e+00      0.011\t|1.088e-01      0.999\n",
      "        wood\t|6.987e+01      0.000\t|3.205e+00      0.000\t|2.154e-01      0.997\n"
     ]
    }
   ],
   "source": [
    "for i in range(no_of_columns, len(joined.columns), no_of_columns):\n",
    "    print(line_1 % tuple(joined.columns[i-no_of_columns:i]))\n",
    "    print(line_2)\n",
    "    print('=' * 22 * (no_of_columns + 1))\n",
    "    for j, surface in zip(range(0,9), encoder.inverse_transform(list(range(0, 9)))):\n",
    "        row = anovas[j][2*(i-no_of_columns):2*i]\n",
    "        print(line_3 % tuple([surface] + anovas[j][2*(i-no_of_columns):2*i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we can get out of the above table! For each combination of surface material and feature, we have the F-statistic and p-value for a one-way ANOVA that was calculated across samples taken during different recording sessions. In other words, for each surface material we asked, if the means of the features are the same across different recording sessions. A low p-value close to zero corresponds to the answer 'no' and we can assume, that the means are not very similar. A high p-value gives us a hint at similar means.\n",
    "\n",
    "At first we notice, that for the hard_tiles material, ANOVA didn't provide us with results. This is due to the fact, we have only one sample for hard_tiles in our dataset. ANOVA is therefore obsolete in this case.\n",
    "\n",
    "Looking at the second row in table 1, we can sanity-check our calculations. The p-value for equal means of the measurement_id's is 1. This makes sense, because for each sample the measurement_id's are just integers from 0 to 127 and the means thus equal across all samples.\n",
    "\n",
    "We can now have a look at the more interesting parts of the above tables. For many entries, we have very extreme values for F and thus p-values very close to 0 (so close, that for many entries we actually cut off the non-zero decimals while formatting). For these values, we have to reject the hypothesis of equal means.\n",
    "\n",
    "But there's also a few tests, that indicate similar means:\n",
    "\n",
    "Samples of velocity_X for carpet, concrete, hard_tiles_large and tiled materials (with p-values of 0.725, 0.953, 0.960 and 0.97 respectively).\n",
    "Samples of acceleration_Z for carpet, concrete, fine_concrete, hard_tiles_large, tiled and wood (with p-values of 0.519, 1, 0.951, 0.989, 0.999, 0.997 respectively).\n",
    "Interesting to note are also some of the tests, where our hypothesis of similar means has to be rejected even a very low significance levels. I leave it up to the reader to interpret the above results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
